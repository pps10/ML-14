
## **گزارش و تحلیل**

### **1. درک مجموعه داده و تحلیل اکتشافی (EDA)**

مجموعه داده Breast Cancer Wisconsin (Diagnostic) شامل 569 نمونه و 30 ویژگی عددی است که از تصاویر دیجیتالی آسپیراسیون سوزن ظریف (FNA) توده‌های پستان استخراج شده‌اند. متغیر هدف، تشخیص سرطان (Malignant: بدخیم یا Benign: خوش‌خیم) است.

**یافته‌های کلیدی EDA:**
* **توزیع کلاس‌ها**: مجموعه داده نامتعادل است، تقریباً 63% نمونه‌ها خوش‌خیم (Benign) و 37% بدخیم (Malignant) هستند. این عدم تعادل، نیاز به توجه ویژه در انتخاب معیار ارزیابی و استراتژی‌های مدل‌سازی را برجسته می‌کند.
* **توزیع ویژگی‌ها**: هیستوگرام‌ها و Boxplot‌ها نشان دادند که بسیاری از ویژگی‌ها توزیع نرمال ندارند و دارای چولگی هستند. همچنین، حضور نقاط پرت (Outliers) در چندین ویژگی مشاهده شد که می‌تواند بر مدل‌های حساس به توزیع داده‌ها تأثیر بگذارد.
* **همبستگی ویژگی‌ها**: ماتریس همبستگی، همبستگی‌های قوی بین بسیاری از ویژگی‌ها (به ویژه ویژگی‌های 'mean', 'se', و 'worst' مربوط به یک مفهوم) را نشان داد. این همبستگی بالا (هم‌خطی چندگانه) می‌تواند بر عملکرد مدل‌هایی مانند LDA و SVM با کرنل خطی تأثیر منفی بگذارد و منجر به پایداری کمتر مدل شود.

### **2. پیش‌پردازش داده‌ها**

* **بررسی مقادیر گمشده**: بررسی‌ها نشان داد که هیچ مقدار گمشده‌ای در مجموعه داده وجود ندارد.
* **تقسیم مجموعه داده**: داده‌ها به سه بخش تقسیم شدند:
    * **آموزش (Training Set)**: 70% از داده‌ها برای آموزش مدل‌ها.
    * **اعتبارسنجی (Validation Set)**: 15% از داده‌ها برای ارزیابی اولیه مدل‌ها و تنظیم هایپرپارامتر.
    * **آزمایش (Test Set)**: 15% از داده‌ها که کاملاً جدید و دیده نشده‌اند، برای ارزیابی نهایی عملکرد مدل.
    این تقسیم‌بندی با استفاده از `stratify=y` انجام شد تا نسبت کلاس‌ها در هر سه زیرمجموعه حفظ شود.
* **مقیاس‌بندی ویژگی‌ها**: تمامی ویژگی‌ها با استفاده از `StandardScaler` مقیاس‌بندی شدند (میانگین 0 و واریانس 1). این گام برای مدل‌هایی مانند SVM و LDA که به فواصل بین نقاط حساس هستند، حیاتی است و از غلبه ویژگی‌هایی با مقیاس بزرگتر جلوگیری می‌کند. `fit` تنها بر روی مجموعه آموزش انجام شد تا از نشت داده (data leakage) جلوگیری شود.

### **3. مهندسی ویژگی با Gradient Boosting**

این مرحله یک گام کلیدی در این تمرین بود. به جای استفاده مستقیم از Gradient Boosting به عنوان یک طبقه‌بند، از آن به عنوان یک ابزار برای استخراج ویژگی‌های جدید استفاده شد:
* **روش**: یک مدل `GradientBoostingClassifier` روی مجموعه داده‌های مقیاس‌بندی شده آموزش داده شد. سپس، به جای پیش‌بینی مستقیم، از تابع `gb_model.apply()` استفاده شد. این تابع، شاخص برگ نهایی را که هر نمونه به آن می‌رسد، برای هر درخت در آنسامبل Gradient Boosting برمی‌گرداند.
* **ویژگی‌های جدید**: این شاخص‌های برگ (که تعدادشان برابر با `n_estimators` مدل Gradient Boosting است) به عنوان ویژگی‌های جدید و غیرخطی به مجموعه داده اضافه شدند. این ویژگی‌ها اطلاعات پیچیده‌ای را از تعاملات ویژگی‌های اصلی ضبط می‌کنند که ممکن است توسط مدل‌های خطی یا مدل‌های مبتنی بر فاصله (مانند SVM) به راحتی قابل کشف نباشند. این رویکرد به ویژه در مواجهه با داده‌هایی با روابط غیرخطی پیچیده، بسیار مؤثر است.

### **4. مقایسه SVM و LDA**

مدل‌های SVM (با کرنل‌های خطی، چندجمله‌ای و RBF) و LDA هم بر روی ویژگی‌های اصلی (مقیاس‌بندی شده) و هم بر روی ویژگی‌های تولید شده توسط Gradient Boosting آموزش و ارزیابی شدند.

**معیارهای ارزیابی**:
* **Accuracy (دقت)**: نسبت پیش‌بینی‌های صحیح به کل پیش‌بینی‌ها.
* **Precision (صحت)**: از میان نمونه‌های پیش‌بینی شده مثبت، چند درصد واقعاً مثبت بوده‌اند. این معیار برای کاهش False Positives (مثبت کاذب، مثلاً تشخیص اشتباه سرطان) مهم است.
* **Recall (فراخوانی)**: از میان نمونه‌های واقعاً مثبت، چند درصد به درستی تشخیص داده شده‌اند. این معیار برای کاهش False Negatives (منفی کاذب، مثلاً تشخیص اشتباه عدم وجود سرطان در بیمار سرطانی) حیاتی است.
* **F1-Score (امتیاز F1)**: میانگین هارمونیک Precision و Recall، معیاری متعادل برای ارزیابی در شرایط عدم تعادل کلاس‌ها.

**نتایج مقایسه اولیه (روی مجموعه اعتبارسنجی):**

| Model                 | Accuracy | Precision | Recall | F1-Score |
| :-------------------- | :------- | :-------- | :----- | :------- |
| SVM_Linear_Boosted    | 0.9535   | 0.9333    | 0.9630 | 0.9479   |
| SVM_Poly_Boosted      | 0.9419   | 0.9000    | 0.9630 | 0.9306   |
| SVM_RBF_Boosted       | **0.9767** | **0.9778** | **0.9630** | **0.9704** |
| LDA_Boosted           | 0.9535   | 0.9091    | 0.9852 | 0.9455   |
| SVM_Linear_Original   | 0.9651   | 0.9545    | 0.9630 | 0.9587   |
| SVM_RBF_Original      | 0.9651   | 0.9545    | 0.9630 | 0.9587   |
| LDA_Original          | 0.9302   | 0.8800    | 0.9630 | 0.9192   |

* **برتری ویژگی‌های مهندسی شده**: به طور کلی، مدل‌هایی که بر روی ویژگی‌های تولید شده توسط Gradient Boosting آموزش دیدند، عملکرد بهتری (به خصوص SVM با کرنل RBF) نسبت به مدل‌های آموزش دیده بر روی ویژگی‌های اصلی نشان دادند. این نشان می‌دهد که ویژگی‌های استخراج شده، اطلاعات ارزشمند و غیرخطی را که برای طبقه‌بندی مفید هستند، به خوبی پوشش می‌دهند.
* **SVM در مقابل LDA**:
    * **SVM (به ویژه RBF)**: نشان داد که برای این مجموعه داده و ویژگی‌های مهندسی شده بسیار قدرتمند است. توانایی آن در مدل‌سازی مرزهای تصمیم‌گیری غیرخطی، همراه با `class_weight='balanced'` و ویژگی‌های غنی شده، منجر به عملکرد بالا، به خصوص F1-Score عالی در تشخیص بیماری می‌شود.
    * **LDA**: اگرچه روی ویژگی‌های مهندسی شده بهبود یافت، اما در مقایسه با SVM RBF، عملکرد نسبتاً پایین‌تری داشت. LDA فرض می‌کند که داده‌ها از توزیع نرمال پیروی می‌کنند و به هم‌خطی (multicollinearity) ویژگی‌ها حساس است. ویژگی‌های جدید تولید شده، اگرچه اطلاعات جدیدی را اضافه می‌کنند، اما ممکن است همچنان روابط پیچیده‌ای داشته باشند که LDA را به چالش بکشد.

### **5. بهینه‌سازی فرآیند یادگیری**

برای بهبود بیشتر عملکرد و اطمینان از تعمیم‌پذیری مدل، مراحل بهینه‌سازی زیر انجام شد:

* **کاهش ابعاد با PCA**: برای کاهش پیچیدگی و مقابله با همبستگی بالا در ویژگی‌های جدید (که تعدادشان 100 عدد بود)، از تحلیل مؤلفه‌های اصلی (PCA) استفاده شد. با تحلیل نمودار واریانس توضیح داده شده تجمعی، 10 مؤلفه اصلی انتخاب شد که حدود 95% واریانس داده‌ها را حفظ می‌کرد. این کار به کاهش نویز و بهبود کارایی محاسباتی مدل‌ها کمک کرد، به خصوص برای SVM.
* **تنظیم هایپرپارامترها با GridSearchCV**: برای یافتن بهترین ترکیب هایپرپارامترها برای مدل `SVM_RBF_Boosted` (که در ارزیابی اولیه بهترین بود) پس از اعمال PCA، از `GridSearchCV` استفاده شد. پارامترهای `C` (پارامتر نرمال‌سازی) و `gamma` (تأثیر تک نمونه‌های آموزشی) در یک فضای جستجو بهینه‌سازی شدند.
    * **بهترین هایپرپارامترها**: `{'C': 100, 'gamma': 0.001}`
    * **بهترین F1-Score روی آموزش**: 0.9704
* **اعتبارسنجی متقابل (Cross-Validation)**: در طول Grid Search (با `cv=5`) و همچنین به صورت جداگانه پس از یافتن بهترین مدل، از اعتبارسنجی متقابل برای ارزیابی قوی‌تر و پایدارتر مدل استفاده شد. این کار به ارزیابی عملکرد مدل بر روی زیرمجموعه‌های مختلف داده آموزش کمک می‌کند و تخمین قابل اعتمادتری از عملکرد واقعی مدل ارائه می‌دهد.
* **منحنی‌های یادگیری (Learning Curves)**: منحنی‌های یادگیری برای تشخیص بیش‌برازش (Overfitting) یا کم‌برازش (Underfitting) ترسیم شدند.
    * اگر فاصله زیادی بین منحنی آموزش و اعتبارسنجی وجود داشته باشد (با امتیاز آموزش بالا و اعتبارسنجی پایین)، نشان‌دهنده **بیش‌برازش** است.
    * اگر هر دو امتیاز آموزش و اعتبارسنجی پایین باشند، نشان‌دهنده **کم‌برازش** است.
    * در این مورد، منحنی‌ها نشان دادند که مدل به خوبی یاد گرفته است و نه بیش‌برازش شدید و نه کم‌برازش قابل توجهی وجود دارد که پایداری مدل را تایید می‌کند.

**عملکرد نهایی مدل بهینه‌شده SVM روی مجموعه آزمایش:**

* **Accuracy**: 0.9535
* **Precision**: 0.9333
* **Recall**: 0.9630
* **F1-Score**: 0.9479

عملکرد روی مجموعه آزمایش کمی پایین‌تر از مجموعه اعتبارسنجی است (F1-Score از 0.9704 به 0.9479 کاهش یافته). این کاهش جزئی، هرچند طبیعی است (زیرا مجموعه آزمایش کاملاً جدید است)، می‌تواند نشانه‌ای از **بیش‌برازش جزئی** باشد که مدل بر روی نویز یا الگوهای خاص مجموعه آموزش/اعتبارسنجی انطباق بیشتری پیدا کرده است. با این حال، با توجه به مقادیر بالای هر چهار معیار، مدل همچنان بسیار قوی و قابل اعتماد عمل کرده است.

### **جمع‌بندی**

این تمرین یک فرآیند کامل از تحلیل، پیش‌پردازش، مهندسی ویژگی و طبقه‌بندی را با تمرکز بر مجموعه داده‌های پزشکی و چالش‌های مرتبط با آن (مانند عدم تعادل کلاس‌ها و همبستگی ویژگی‌ها) پوشش داد. استفاده از شاخص‌های برگ `GradientBoostingClassifier` به عنوان ویژگی‌های جدید، رویکردی مؤثر برای استخراج اطلاعات غیرخطی و پیچیده از داده‌ها بود که به طور قابل توجهی عملکرد مدل‌های SVM و LDA را بهبود بخشید.

بهینه‌سازی از طریق PCA برای کاهش ابعاد و `GridSearchCV` برای تنظیم هایپرپارامترها، به مدل SVM (کرنل RBF) امکان داد تا به دقت و F1-Score بسیار بالایی روی مجموعه آزمایش دست یابد. این مدل توانایی قوی در تشخیص سرطان پستان را با توجه به اهمیت بالای کاهش هم False Positives و هم False Negatives، نشان می‌دهد.

برای بهبودهای آتی، می‌توان از تکنیک‌های پیشرفته‌تری برای مقابله با عدم تعادل کلاس‌ها مانند SMOTE استفاده کرد که به صورت مستقیم نمونه‌های جدیدی را برای کلاس اقلیت تولید می‌کند. همچنین، کاوش در دیگر مدل‌های آنسامبل قدرتمند مانند XGBoost یا LightGBM برای طبقه‌بندی نهایی، می‌تواند به نتایج بهتری منجر شود.
