این متن به صورت Markdown برای GitHub آماده شده است.

---

# رگرسیون لجستیک و کاهنده گرادیان: حل گام به گام

در پاسخ به پرسش شما در مورد **سوال ۱ منبع exam1** و با تشریح کامل مراحل حل ریاضی به همراه محاسبات گام به گام و ارائه جواب نهایی، از داده‌های ارائه شده در **منبع [۲]** استفاده می‌کنیم:

| A ($x_1$) | B ($x_2$) | Label (y) |
| :-------: | :-------: | :-------: |
| 1 | 0 | 0 |
| 0 | 1 | 0 |
| -1 | 0 | 1 |
| 0 | -1 | 1 |

هدف این است که با استفاده از **طبقه‌بندی رگرسیون لجستیک (Logistic Regression)**، ضرایب ($w$ و $b$) را از طریق **کاهنده گرادیان (Gradient Descent)** محاسبه کنیم [۱].

---

## الف) طبقه‌بندی رگرسیون لجستیک

رگرسیون لجستیک احتمال تعلق یک نمونه به کلاس مثبت (۱) را تخمین می‌زند [۹۰, ۸۴]. مراحل آن:

1.  **ورودی خالص (Net Input) - z:**
    $z = w_1 * x_1 + w_2 * x_2 + b$ [۴۱]
2.  **تابع سیگموئید (Sigmoid Function) - $\sigma(z)$:**
    $\sigma(z) = \frac{1}{(1 + e^{-z})}$ [۸۸]

    این تابع خروجی $z$ را به مقادیر احتمالی بین ۰ و ۱ تبدیل می‌کند [۸۸]. $\sigma(z)$ به عنوان $p(y=1|x)$ (احتمال تعلق به کلاس ۱) تفسیر می‌شود [۹۰].
3.  **تصمیم‌گیری طبقه‌بندی:**
    اگر $\sigma(z) \geq 0.5$ باشد، مدل پیش‌بینی می‌کند که نمونه متعلق به کلاس ۱ است [۹۱]. در غیر این صورت، مدل پیش‌بینی می‌کند که نمونه متعلق به کلاس ۰ است [۹۱]. این معادل است با: اگر $z \geq 0$، $y_{pred} = 1$ و در غیر این صورت $y_{pred} = 0$ [۹۱].
4.  **تابع زیان (Loss Function) - کراس‌انتروپی لجستیک:**
    برای آموزش مدل، تابع زیان کراس‌انتروپی را به حداقل می‌رسانیم [۹۲, ۹۴]:
    $L(w, b) = \Sigma[−y^{(i)} \log(\sigma(z^{(i)})) − (1 − y^{(i)}) \log(1 − \sigma(z^{(i)}))]$ [۹۴]
    این تابع پیش‌بینی‌های نادرست را با زیان بیشتری جریمه می‌کند [۹۹].

---

## ب) منظم‌سازی (Regularization)

**منظم‌سازی** روشی برای مقابله با **بیش‌برازش (overfitting)** است که مدل را قادر می‌سازد تا به داده‌های جدید نیز خوب تعمیم یابد [۷۴, ۱۲۲]. این کار با افزودن یک جمله جریمه (penalty term) به تابع زیان اصلی انجام می‌شود [۷۴].

**انواع متداول منظم‌سازی:**
* **منظم‌سازی L1 (LASSO):** جمله جریمه متناسب با مجموع قدر مطلق وزن‌ها است ($\lambda * \Sigma|w_j|$). این روش می‌تواند برخی از وزن‌ها را به صفر برساند و به انتخاب ویژگی کمک می‌کند [۱۳۶].
* **منظم‌سازی L2 (Ridge Regression):** جمله جریمه متناسب با مجموع مربع وزن‌ها است ($\lambda * \Sigma(w_j)^2$). این روش وزن‌ها را به سمت صفر کوچک می‌کند اما معمولاً آن‌ها را کاملاً صفر نمی‌کند [۱۳۵, ۱۳۶].

**پارامتر منظم‌سازی ($\lambda$ یا C):**
قدرت منظم‌سازی توسط یک **هایپرپارامتر** کنترل می‌شود [۷۴, ۱۰۵]. افزایش قدرت منظم‌سازی (افزایش $\lambda$ یا کاهش C) **بایاس** مدل را افزایش و **واریانس (بیش‌برازش)** را کاهش می‌دهد [۱۱۰].

---

## ج) محاسبه ضرایب با استفاده از کاهنده گرادیان (Gradient Descent)

کاهنده گرادیان یک **الگوریتم بهینه‌سازی تکراری** است که برای یافتن پارامترهای مدل (وزن‌ها $w$ و بایاس $b$) که تابع زیان را به حداقل می‌رسانند، استفاده می‌شود [۶۳, ۳۰۴].

**مراحل کلی الگوریتم:**
1.  **مقداردهی اولیه پارامترها:** وزن‌ها و بایاس با مقادیر اولیه (معمولاً صفر یا اعداد تصادفی کوچک) مقداردهی می‌شوند [۴۳, ۵۲].
2.  **تکرار (Epochs):** الگوریتم برای تعداد مشخصی از تکرارها اجرا می‌شود [۴۳].
3.  **بروزرسانی پارامترها:** پارامترها در جهت مخالف گرادیان تابع زیان (جهت تندترین کاهش تابع) بروزرسانی می‌شوند [۶۵, ۳۰۴]. **نرخ یادگیری ($\eta$)** اندازه این گام را کنترل می‌کند [۴۴].

**فرمول‌های بروزرسانی (بدون منظم‌سازی برای سادگی محاسبات دستی) [۲, ۱۰۳]:**
$\frac{\partial L}{\partial w_j} = \Sigma[(\sigma(z^{(i)}) - y^{(i)}) * x_j^{(i)}]$
$\frac{\partial L}{\partial b} = \Sigma[(\sigma(z^{(i)}) - y^{(i)})]$

$w_j := w_j - \eta * \frac{\partial L}{\partial w_j}$
$b := b - \eta * \frac{\partial L}{\partial b}$

---

## محاسبات گام به گام و جواب نهایی

برای انجام محاسبات، فرضیات زیر را در نظر می‌گیریم:
* **مقادیر اولیه پارامترها:** $w_1 = 0$، $w_2 = 0$، $b = 0$ [۴۳, ۵۲]
* **نرخ یادگیری (Learning Rate):** $\eta = 0.1$ (یک مقدار رایج در مثال‌ها [۴۹, ۶۸, ۷۵])
* **منظم‌سازی:** در این محاسبات گام به گام، برای سادگی و وضوح، جمله جریمه منظم‌سازی را در نظر نمی‌گیریم. (اگر منظم‌سازی L2 اعمال می‌شد، جملات $2 * \lambda * w_j$ به مشتقات $w_j$ اضافه می‌شدند [۱۰۵].)

**داده‌ها:**
| Sample (i) | $x_1$ | $x_2$ | y |
| :---------: | :-: | :-: | :-: |
| 1 | 1 | 0 | 0 |
| 2 | 0 | 1 | 0 |
| 3 | -1 | 0 | 1 |
| 4 | 0 | -1 | 1 |

### **Epoch 1:**

**گام ۱: محاسبه $z^{(i)}$ و $\sigma(z^{(i)})$ و $(\sigma(z^{(i)}) - y^{(i)})$ برای هر نمونه**
* **نمونه ۱ ($x_1 = 1, x_2 = 0, y = 0$):**
    $z^{(1)} = (0 * 1) + (0 * 0) + 0 = 0$
    $\sigma(z^{(1)}) = \frac{1}{(1 + e^0)} = \frac{1}{(1 + 1)} = 0.5$
    $Error\_term^{(1)} = \sigma(z^{(1)}) - y^{(1)} = 0.5 - 0 = 0.5$
* **نمونه ۲ ($x_1 = 0, x_2 = 1, y = 0$):**
    $z^{(2)} = (0 * 0) + (0 * 1) + 0 = 0$
    $\sigma(z^{(2)}) = \frac{1}{(1 + e^0)} = 0.5$
    $Error\_term^{(2)} = \sigma(z^{(2)}) - y^{(2)} = 0.5 - 0 = 0.5$
* **نمونه ۳ ($x_1 = -1, x_2 = 0, y = 1$):**
    $z^{(3)} = (0 * -1) + (0 * 0) + 0 = 0$
    $\sigma(z^{(3)}) = \frac{1}{(1 + e^0)} = 0.5$
    $Error\_term^{(3)} = \sigma(z^{(3)}) - y^{(3)} = 0.5 - 1 = -0.5$
* **نمونه ۴ ($x_1 = 0, x_2 = -1, y = 1$):**
    $z^{(4)} = (0 * 0) + (0 * -1) + 0 = 0$
    $\sigma(z^{(4)}) = \frac{1}{(1 + e^0)} = 0.5$
    $Error\_term^{(4)} = \sigma(z^{(4)}) - y^{(4)} = 0.5 - 1 = -0.5$

**گام ۲: محاسبه گرادیان‌ها**
$\frac{\partial L}{\partial w_1} = (0.5 * 1) + (0.5 * 0) + (-0.5 * -1) + (-0.5 * 0) = 0.5 + 0 + 0.5 + 0 = 1.0$
$\frac{\partial L}{\partial w_2} = (0.5 * 0) + (0.5 * 1) + (-0.5 * 0) + (-0.5 * -1) = 0 + 0.5 + 0 + 0.5 = 1.0$
$\frac{\partial L}{\partial b} = 0.5 + 0.5 + (-0.5) + (-0.5) = 0$

**گام ۳: بروزرسانی پارامترها**
$w_1 := w_1 - \eta * \frac{\partial L}{\partial w_1} = 0 - (0.1 * 1.0) = -0.1$
$w_2 := w_2 - \eta * \frac{\partial L}{\partial w_2} = 0 - (0.1 * 1.0) = -0.1$
$b := b - \eta * \frac{\partial L}{\partial b} = 0 - (0.1 * 0) = 0$

**پارامترهای پس از Epoch 1:**
* $w_1 = -0.1$
* $w_2 = -0.1$
* $b = 0$

### **Epoch 2:**

**گام ۱: محاسبه $z^{(i)}$ و $\sigma(z^{(i)})$ و $(\sigma(z^{(i)}) - y^{(i)})$ برای هر نمونه (با استفاده از $w_1 = -0.1, w_2 = -0.1, b = 0$)**
* **نمونه ۱ ($x_1 = 1, x_2 = 0, y = 0$):**
    $z^{(1)} = (-0.1 * 1) + (-0.1 * 0) + 0 = -0.1$
    $\sigma(z^{(1)}) = \frac{1}{(1 + e^{-(-0.1)})} = \frac{1}{(1 + e^{0.1})} \approx \frac{1}{(1 + 1.105)} \approx 0.475$
    $Error\_term^{(1)} = 0.475 - 0 = 0.475$
* **نمونه ۲ ($x_1 = 0, x_2 = 1, y = 0$):**
    $z^{(2)} = (-0.1 * 0) + (-0.1 * 1) + 0 = -0.1$
    $\sigma(z^{(2)}) \approx 0.475$
    $Error\_term^{(2)} = 0.475 - 0 = 0.475$
* **نمونه ۳ ($x_1 = -1, x_2 = 0, y = 1$):**
    $z^{(3)} = (-0.1 * -1) + (-0.1 * 0) + 0 = 0.1$
    $\sigma(z^{(3)}) = \frac{1}{(1 + e^{-0.1})} \approx \frac{1}{(1 + 0.905)} \approx 0.525$
    $Error\_term^{(3)} = 0.525 - 1 = -0.475$
* **نمونه ۴ ($x_1 = 0, x_2 = -1, y = 1$):**
    $z^{(4)} = (-0.1 * 0) + (-0.1 * -1) + 0 = 0.1$
    $\sigma(z^{(4)}) \approx 0.525$
    $Error\_term^{(4)} = 0.525 - 1 = -0.475$

**گام ۲: محاسبه گرادیان‌ها**
$\frac{\partial L}{\partial w_1} = (0.475 * 1) + (0.475 * 0) + (-0.475 * -1) + (-0.475 * 0) = 0.475 + 0 + 0.475 + 0 = 0.95$
$\frac{\partial L}{\partial w_2} = (0.475 * 0) + (0.475 * 1) + (-0.475 * 0) + (-0.475 * -1) = 0 + 0.475 + 0 + 0.475 = 0.95$
$\frac{\partial L}{\partial b} = 0.475 + 0.475 + (-0.475) + (-0.475) = 0$

**گام ۳: بروزرسانی پارامترها**
$w_1 := w_1 - \eta * \frac{\partial L}{\partial w_1} = -0.1 - (0.1 * 0.95) = -0.1 - 0.095 = -0.195$
$w_2 := w_2 - \eta * \frac{\partial L}{\partial w_2} = -0.1 - (0.1 * 0.95) = -0.1 - 0.095 = -0.195$
$b := b - \eta * \frac{\partial L}{\partial b} = 0 - (0.1 * 0) = 0$

**پارامترهای پس از Epoch 2:**
* $w_1 = -0.195$
* $w_2 = -0.195$
* $b = 0$

---

## جواب نهایی و تحلیل

با توجه به ماهیت تکراری الگوریتم کاهنده گرادیان، "جواب نهایی" به معنای مقادیری از پارامترها است که پس از تعداد کافی تکرار (epochs) به یک مقدار حداقل همگرا شده‌اند [۴۹, ۶۳]. در اینجا، پس از دو دور تکرار، مقادیر ضرایب به شرح زیر است:

* **ضریب $w_1$ (برای ویژگی A) = -0.195**
* **ضریب $w_2$ (برای ویژگی B) = -0.195**
* **بایاس $b$ = 0**

همانطور که مشاهده می‌شود، وزن‌ها $w_1$ و $w_2$ در حال کاهش (منفی‌تر شدن) هستند، در حالی که بایاس $b$ همچنان صفر باقی مانده است. این نشان‌دهنده همگرایی تدریجی پارامترها در جهت کاهش تابع زیان است [۶۹]. صفر ماندن بایاس در این مثال خاص به دلیل تقارن داده‌ها حول محور y=0 و مقادیر اولیه صفر برای وزن‌ها و بایاس است، که منجر به مشتق صفر بایاس در هر گام می‌شود. در یک اجرای کامل، این فرآیند برای تعداد مشخصی از epochs (مثلاً ۵۰ یا ۱۰۰۰ دور) ادامه می‌یابد تا پارامترها به مقادیر بهینه همگرا شوند [۴۹, ۱۰۱].

برای افزایش دقت و جلوگیری از بیش‌برازش، می‌توان از تکنیک‌های منظم‌سازی (مانند L1 یا L2) استفاده کرد. در صورت استفاده از منظم‌سازی L2، قوانین بروزرسانی وزن‌ها ($w_j$) شامل یک جمله اضافی $2 * \lambda * w_j$ در گرادیان خواهد بود، که وزن‌ها را به سمت صفر کوچک می‌کند [۱۰۵, ۱۳۶]. انتخاب مناسب نرخ یادگیری نیز برای همگرایی بهینه بسیار مهم است؛ نرخ یادگیری بیش از حد بزرگ می‌تواند باعث پرش از حداقل شود، در حالی که نرخ یادگیری بسیار کوچک باعث کندی همگرایی می‌شود [۶۹, ۷۰].





---

**سوال ۲ –**  
داده‌های جدول زیر را در نظر بگیرید. با استفاده از روش **ماشین بردار پشتیبان (SVM)** برای طبقه‌بندی داده‌ها، به سؤالات زیر پاسخ دهید.

### جدول داده‌ها:

| \( i \)       | \( X_1 \) | \( X_2 \) | \( Y \) | \( \alpha_i \) |
|---------------|----------|----------|--------|----------------|
| \( x_1 \)     | 8.0      | 5.8      | 1      | 0.414          |
| \( x_2 \)     | 8.0      | 8.0      | 1      | 0.000          |
| \( x_3 \)     | 2.0      | 5.0      | -1     | 0.000          |
| \( x_4 \)     | 5.0      | 2.0      | -1     | 0.018          |
| \( x_5 \)     | 9.8      | 9.0      | 1      | 0.000          |
| \( x_6 \)     | 3.8      | 3.8      | -1     | 0.000          |
| \( x_7 \)     | 7.0      | 8.0      | 1      | 0.018          |
| \( x_8 \)     | 1.0      | 3.0      | -1     | 0.000          |
| \( x_9 \)     | 4.0      | 4.2      | -1     | 0.414          |
| \( x_{10} \)  | 9.0      | 5.0      | 1      | 0.000          |

---

### فرضیات:
- مدل SVM با **تابع تصمیم خطی** \( h(\mathbf{x}) \) آموزش داده شده است.
- هدف، محاسبه **مارژین (Margin)** و بررسی وضعیت نقاط نسبت به مرز تصمیم است.
- همچنین، مقدار \( h(\mathbf{x}) \) برای نقطهٔ تست \( \mathbf{x} = (3, 3)^T \) باید محاسبه شود.

---

### سؤالات:

**الف)** تابع تصمیم \( h(\mathbf{x}) \) را برای این مدل SVM به دست آورید.  
نحوه محاسبه آن را با استفاده از فرمول زیر و داده‌های جدول (به‌ویژه نقاط با \( \alpha_i > 0 \)) توضیح دهید:

\[
h(\mathbf{x}) = \sum_{i=1}^{n} \alpha_i y_i \mathbf{x}_i^T \mathbf{x} + b
\]

در اینجا، فقط نقاطی که \( \alpha_i > 0 \) هستند (یعنی **بردارهای پشتیبان**) در محاسبه تأثیر دارند.

---

**ب)** فاصله نقطه \( x_6 = (3.8, 3.8)^T \) نسبت به مرز تصمیم (یعنی مقدار **مارژین نسبی** \( \delta \)) را محاسبه کنید.  
آیا این نقطه یک **بردار پشتیبان (Support Vector)** است؟ چرا؟

راهنمایی: از فرمول زیر استفاده کنید:

\[
\delta = \frac{y_i \cdot h(\mathbf{x}_i)}{\|\mathbf{w}\|}
\]

---

**پ)** مقدار تابع تصمیم \( h(\mathbf{x}) \) را برای نقطهٔ تست \( \mathbf{x} = (3, 3)^T \) محاسبه کنید.  
سپس، برچسب پیش‌بینی‌شدهٔ آن (مثبت یا منفی) را مشخص کنید.

---

✅ **نکته:**  
- بردار وزن \( \mathbf{w} \) از رابطه \( \mathbf{w} = \sum \alpha_i y_i \mathbf{x}_i \) به دست می‌آید.  
- مقدار \( b \) (بایاس) را می‌توان با استفاده از یکی از بردارهای پشتیبان (مثلاً \( x_1 \) یا \( x_9 \)) و رابطه \( h(\mathbf{x}_i) = y_i \) محاسبه کرد.

---
```markdown
### الف) تابع تصمیم \( h(\mathbf{x}) \)

تابع تصمیم برای یک SVM خطی به شکل  
\[
h(\mathbf{x}) = \mathbf{w}^\mathsf{T}\mathbf{x} + b
\]  
تعریف می‌شود. بردار وزن \( \mathbf{w} \) و بایاس \( b \) با استفاده از بردارهای پشتیبان و ضرایب \( \alpha_i \) محاسبه می‌شوند.

#### شناسایی بردارهای پشتیبان
نمونه‌هایی که \( \alpha_i > 0 \) هستند:

| نقطه | مختصات | برچسب \( y_i \) | \( \alpha_i \) |
|------|---------|-----------------|----------------|
| \( \mathbf{x}_1 \) | \( (8, 5.8) \) | \( +1 \) | 0.414 |
| \( \mathbf{x}_4 \) | \( (5, 2) \)   | \( -1 \) | 0.018 |
| \( \mathbf{x}_7 \) | \( (7, 8) \)   | \( +1 \) | 0.018 |
| \( \mathbf{x}_9 \) | \( (4, 4.2) \) | \( -1 \) | 0.414 |

#### محاسبه بردار وزن \( \mathbf{w} \)
\[
\mathbf{w} = \sum_{i \in \text{SV}} \alpha_i y_i \mathbf{x}_i
\]

\[
\begin{aligned}
\mathbf{w} &= 0.414(+1)\begin{pmatrix}8 \\ 5.8\end{pmatrix}
            + 0.018(-1)\begin{pmatrix}5 \\ 2\end{pmatrix}
            + 0.018(+1)\begin{pmatrix}7 \\ 8\end{pmatrix}
            + 0.414(-1)\begin{pmatrix}4 \\ 4.2\end{pmatrix} \\[4pt]
&= \begin{pmatrix}3.312 \\ 2.3952\end{pmatrix}
 + \begin{pmatrix}-0.090 \\ -0.036\end{pmatrix}
 + \begin{pmatrix}0.126 \\ 0.144\end{pmatrix}
 + \begin{pmatrix}-1.656 \\ -1.7388\end{pmatrix} \\[4pt]
&= \begin{pmatrix}1.692 \\ 0.7644\end{pmatrix}
\end{aligned}
\]

#### محاسبه بایاس \( b \)
با استفاده از \( \mathbf{x}_4 \) (که \( \alpha \) کوچک‌تری دارد):

\[
-1 \cdot \bigl(1.692 \cdot 5 + 0.7644 \cdot 2 + b\bigr) = 1
\Longrightarrow b = -10.9888
\]

بنابراین تابع تصمیم:

\[
\boxed{h(\mathbf{x}) = 1.692\,x_1 + 0.7644\,x_2 - 10.9888}
\]

---

### ب) فاصله (مارژین) نقطه \( \mathbf{x}_6 \)

- **وضعیت \( \mathbf{x}_6 \):**  
  \( \alpha_6 = 0 \Rightarrow \) **بردار پشتیبان نیست**.

- **محاسبه \( h(\mathbf{x}_6) \):**  
  \[
  h\!\bigl((3.8, 3.8)\bigr) = 1.692 \cdot 3.8 + 0.7644 \cdot 3.8 - 10.9888 \approx -1.6545
  \]

- **نرم بردار وزن:**  
  \[
  \|\mathbf{w}\| = \sqrt{1.692^2 + 0.7644^2} \approx 1.8566
  \]

- **مارژین:**  
  \[
  \delta_6 = \frac{(-1)\cdot(-1.6545)}{1.8566} \approx 0.8911
  \]

\[
\boxed{\delta_6 \approx 0.891 \quad (\text{SV نیست})}
\]

---

### پ) طبقه‌بندی نقطه \( (3,3)^\mathsf{T} \)

\[
h\!\bigl((3,3)\bigr) = 1.692 \cdot 3 + 0.7644 \cdot 3 - 10.9888 \approx -3.6196 < 0
\]

\[
\boxed{(3,3) \text{ در کلاس } -1 \text{ قرار می‌گیرد}}
\]
```
برای طبقه‌بندی داده‌ها به دو دسته `( Y=1 )` و `( Y=0 )` با استفاده از روش تحلیل تفکیک خطی (LDA)، هدف ما پیدا کردن یک فضای ویژگی کاهش‌یافته (در اینجا یک متغیر واحد) است که جدایی‌پذیری کلاس‌ها را بهینه کند [۱۳۸، ۱۶۱]. مراحل انجام این کار به شرح زیر است:

**مراحل LDA:**
۱.  **استانداردسازی مجموعه داده:** داده‌ها باید استاندارد شوند تا میانگین هر ویژگی صفر و واریانس آن یک شود. این کار به پایداری عددی الگوریتم‌های بهینه‌سازی کمک می‌کند [۱۰۶].
۲.  **محاسبه بردارهای میانگین برای هر کلاس:** برای هر کلاس، میانگین ویژگی‌ها را محاسبه می‌کنیم.
۳.  **ساخت ماتریس پراکندگی درون کلاسی `( S_W )` و بین کلاسی `( S_B )`:**
    *   **ماتریس پراکندگی درون کلاسی `( S_W )`:** مجموع پراکندگی نمونه‌ها حول میانگین کلاس‌های خودشان را اندازه‌گیری می‌کند [۱۴۵].
    *   **ماتریس پراکندگی بین کلاسی `( S_B )`:** پراکندگی میانگین کلاس‌ها حول میانگین کلی داده‌ها را اندازه‌گیری می‌کند [۱۴۹].
۴.  **محاسبه مقادیر ویژه (Eigenvalues) و بردارهای ویژه (Eigenvectors) ماتریس `( S_W^{-1} S_B )`:** این مرحله به ما کمک می‌کند جهت‌هایی را پیدا کنیم که جدایی‌پذیری کلاس‌ها را به حداکثر می‌رسانند [۱۵۰].
۵.  **مرتب‌سازی زوج‌های ویژه (Eigenpairs):** مقادیر ویژه را به ترتیب نزولی مرتب می‌کنیم تا بردارهای ویژه مرتبط با بیشترین "اطلاعات تفکیک‌کننده" را شناسایی کنیم [۱۴۲].
۶.  **انتخاب `( k )` بردار ویژه اصلی:** از آنجایی که دو کلاس `( Y=1 )` و `( Y=0 )` داریم، تعداد حداکثر بردارهای تفکیک‌کننده خطی `( c-1 )` است که در اینجا `( 2-1=1 )` می‌شود [۱۵۱]. بنابراین، تنها بردار ویژه مرتبط با بزرگترین مقدار ویژه را انتخاب می‌کنیم. این بردار ویژه، ماتریس تبدیل `( W )` خواهد بود.
۷.  **تصویرسازی (Projection) نمونه‌ها بر روی فضای ویژگی جدید:** داده‌های استاندارد شده را با استفاده از ماتریس تبدیل `( W )` بر روی یک فضای تک‌بعدی جدید تصویر می‌کنیم `( X' = XW )` [۱۵۵].

---

**محاسبات با استفاده از داده‌های جدول:**

**جدول داده‌ها:**

| X1 | X2 | Y |
|----|----|---|
| 2.1 | 0.8 | 1 |
| 1.5 | 0.3 | 0 |
| 0.7 | 1.2 | 1 |
| 0.9 | 0.5 | 0 |
| 1.8 | 1.0 | 1 |
| 0.3 | 0.6 | 0 |

**۱. استانداردسازی مجموعه داده:**
ابتدا داده‌ها را با استفاده از `( StandardScaler )` استاندارد می‌کنیم. این کار باعث می‌شود میانگین هر ویژگی صفر و واریانس آن یک شود.

*   **داده‌های اصلی (X):**
    `X = [[2.1, 0.8], [1.5, 0.3], [0.7, 1.2], [0.9, 0.5], [1.8, 1.0], [0.3, 0.6]]`
*   **داده‌های استاندارد شده (X_std):**
    ```
    [[ 1.4639,  0.2248],  (Y=1)
     [ 0.4709, -1.4566],  (Y=0)
     [-0.8564,  1.5658],  (Y=1)
     [-0.5249, -0.7811],  (Y=0)
     [ 0.9664,  0.8993],  (Y=1)
     [-1.5200, -0.4492]]  (Y=0)
    ```
    (مقادیر به ۴ رقم اعشار گرد شده‌اند)

**۲. محاسبه بردارهای میانگین برای هر کلاس و میانگین کلی:**

*   **نقاط کلاس `( Y=0 )` (بعد از استانداردسازی):** `( [0.4709, -1.4566], [-0.5249, -0.7811], [-1.5200, -0.4492] )`
*   **میانگین کلاس `( Y=0 )` (`( \mu_0 )`):** `( [-0.5247, -0.8956] )`
*   **نقاط کلاس `( Y=1 )` (بعد از استانداردسازی):** `( [1.4639, 0.2248], [-0.8564, 1.5658], [0.9664, 0.8993] )`
*   **میانگین کلاس `( Y=1 )` (`( \mu_1 )`):** `( [0.5246, 0.8966] )`
*   **میانگین کلی (`( \mu_{overall} )`):** `( [0.0000, 0.0000] )` (که پس از استانداردسازی انتظار می‌رود صفر باشد).

**۳. ساخت ماتریس پراکندگی درون کلاسی `( S_W )` و بین کلاسی `( S_B )`:**

*   **ماتریس پراکندگی درون کلاسی `( S_W )`:**
    `( S_W = \begin{pmatrix} 2.35 & -1.10 \\ -1.10 & 0.80 \end{pmatrix} )`
*   **ماتریس پراکندگی بین کلاسی `( S_B )`:**
    `( S_B = \begin{pmatrix} 2.35 & 3.95 \\ 3.95 & 6.65 \end{pmatrix} )`

**۴. محاسبه مقادیر ویژه و بردارهای ویژه ماتریس `( S_W^{-1} S_B )`:**

*   ماتریس `( S_W^{-1} S_B )` به صورت تقریبی زیر است:
    `( \begin{pmatrix} 1.44 & 1.61 \\ 4.40 & 4.85 \end{pmatrix} )`
*   **مقادیر ویژه (Eigenvalues):**
    یکی از مقادیر ویژه تقریباً `( 6.29 )` و دیگری تقریباً `( 0 )` است. این نشان می‌دهد که تنها یک جهت تفکیک‌کننده معنی‌دار وجود دارد، همانطور که انتظار می‌رفت [۱۵۱].

**۵. مرتب‌سازی زوج‌های ویژه:**

*   زوج‌های ویژه به ترتیب نزولی مقادیر ویژه عبارتند از:
    *   `( 6.29, [-0.3061, -0.9519]^T )` (بردار ویژه اصلی)
    *   `( \approx 0, [-0.9519, 0.3061]^T )`

**۶. انتخاب بردار ویژه اصلی:**
بردار ویژه مرتبط با بزرگترین مقدار ویژه (که در اینجا تنها بردار ویژه معنی‌دار است) به عنوان ماتریس تبدیل `( W )` انتخاب می‌شود:
`( W = \begin{pmatrix} -0.3061 \\ -0.9519 \end{pmatrix} )`

**۷. تصویرسازی نمونه‌ها بر روی فضای ویژگی جدید:**
در نهایت، داده‌های استاندارد شده را با ضرب در ماتریس `( W )` بر روی یک متغیر جدید (تک‌بعدی) تصویر می‌کنیم: `( X_{LDA} = X_{std} \cdot W )`.

*   **مقادیر متغیر جدید `( X_{LDA} )` برای هر نقطه:**
    *   برای `( x_1 = (2.1, 0.8)^T )` (`Y=1`): `( 1.4639 \times (-0.3061) + 0.2248 \times (-0.9519) \approx -0.6625 )`
    *   برای `( x_2 = (1.5, 0.3)^T )` (`Y=0`): `( 0.4709 \times (-0.3061) + (-1.4566) \times (-0.9519) \approx 1.2423 )`
    *   برای `( x_3 = (0.7, 1.2)^T )` (`Y=1`): `( -0.8564 \times (-0.3061) + 1.5658 \times (-0.9519) \approx -1.2281 )`
    *   برای `( x_4 = (0.9, 0.5)^T )` (`Y=0`): `( -0.5249 \times (-0.3061) + (-0.7811) \times (-0.9519) \approx 0.9042 )`
    *   برای `( x_5 = (1.8, 1.0)^T )` (`Y=1`): `( 0.9664 \times (-0.3061) + 0.8993 \times (-0.9519) \approx -1.1521 )`
    *   برای `( x_6 = (0.3, 0.6)^T )` (`Y=0`): `( -1.5200 \times (-0.3061) + (-0.4492) \times (-0.9519) \approx 0.8930 )`

**متغیر جدید ایجاد شده `( X_{LDA} )`:**

| نقطه (i) | Y | X_LDA (متغیر جدید) |
|----------|---|--------------------|
| ۱        | ۱ | `-0.6625`          |
| ۲        | ۰ | `1.2423`           |
| ۳        | ۱ | `-1.2281`          |
| ۴        | ۰ | `0.9042`           |
| ۵        | ۱ | `-1.1521`          |
| ۶        | ۰ | `0.8930`           |

همانطور که مشاهده می‌شود، مقادیر `( X_{LDA} )` برای کلاس `( Y=1 )` (تقریباً `-0.66`، `-1.23`، `-1.15`) منفی هستند، در حالی که برای کلاس `( Y=0 )` (تقریباً `1.24`، `0.90`، `0.89`) مثبت هستند. این نشان می‌دهد که می‌توان یک مرز تصمیم (مثلاً `( X_{LDA} = 0 )`) برای جداسازی این دو کلاس در فضای تک‌بعدی جدید ایجاد کرد.

این متغیر جدید، که از ترکیب خطی ویژگی‌های اصلی به دست آمده است، توانایی حداکثری را برای تفکیک دو دسته `( Y=1 )` و `( Y=0 )` فراهم می‌کند.
