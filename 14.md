خدمت شما توضیح کامل فصل ۱۴ از کتاب "Machine Learning with PyTorch and Scikit-Learn" به زبان فارسی و گام‌به‌گام ارائه می‌شود.

---

## فصل 14: طبقه‌بندی تصاویر با شبکه‌های عصبی پیچشی عمیق (Classifying Images with Deep Convolutional Neural Networks)

### 14.1. بلوک‌های سازنده CNN‌ها (The building blocks of CNNs)

**خلاصه:**
این بخش به معرفی شبکه‌های عصبی پیچشی (Convolutional Neural Networks - CNNs) می‌پردازد که نوع خاصی از معماری شبکه‌های عصبی عمیق (Deep Neural Network Architecture) هستند و به طور خاص برای کار با مجموعه‌داده‌های تصویری (Image Datasets) مناسب‌اند. به دلیل عملکرد برتر آن‌ها در مقایسه با روش‌های سنتی، CNN‌ها اکنون به طور گسترده در بینایی کامپیوتر (Computer Vision) برای دستیابی به نتایج پیشرفته در وظایف مختلف تشخیص تصویر (Image Recognition) استفاده می‌شوند. در این فصل، یاد می‌گیرید که چگونه لایه‌های پیچشی (Convolutional Layers) می‌توانند به عنوان استخراج‌کننده‌های ویژگی (Feature Extractors) قدرتمند برای طبقه‌بندی تصاویر (Image Classification) به کار روند.

**معادل‌های فارسی:**
* **شبکه‌های عصبی پیچشی (CNNs):** Convolutional Neural Networks (CNNs)
* **شبکه‌های عصبی عمیق:** Deep Neural Networks
* **بینایی کامپیوتر:** Computer Vision
* **تشخیص تصویر:** Image Recognition
* **لایه‌های پیچشی/کانولوشنی:** Convolutional Layers
* **استخراج‌کننده ویژگی:** Feature Extractor
* **لایه نمونه‌برداری فرعی/پولینگ:** Subsampling Layer / Pooling Layer
* **سلسله‌مراتب ویژگی:** Feature Hierarchies
* **پیچش گسسته:** Discrete Convolution
* **فیلتر/هسته:** Filter / Kernel
* **نقشه ویژگی:** Feature Map
* **پدینگ/هم‌اندازه‌سازی:** Padding

**توضیحات مفاهیم و مثال با کد پایتون:**

#### 14.1.1. درک CNN‌ها و سلسله‌مراتب ویژگی (Understanding CNNs and feature hierarchies)

CNN‌ها از معماری خاصی بهره می‌برند که به آن‌ها اجازه می‌دهد الگوهای سلسله‌مراتبی را در تصاویر شناسایی کنند. در لایه‌های اولیه، CNN‌ها ویژگی‌های ساده‌ای مانند لبه‌ها و گوشه‌ها را تشخیص می‌دهند. با پیشروی به لایه‌های عمیق‌تر، این ویژگی‌های ساده‌تر ترکیب شده و الگوهای پیچیده‌تری مانند بافت‌ها، اشکال و در نهایت اجسام کامل را شناسایی می‌کنند. این رویکرد الهام‌گرفته از نحوه پردازش اطلاعات بصری در قشر بینایی مغز انسان است.

#### 14.1.2. انجام پیچش‌های گسسته (Performing discrete convolutions)

**پیچش گسسته (Discrete Convolution)** یک عملیات بنیادی در CNN است. برای درک این عملیات، ابتدا به پیچش یک‌بعدی (One-dimensional Convolution) می‌پردازیم که گاهی برای داده‌های ترتیبی مانند متن استفاده می‌شود. سپس پیچش دوبعدی (Two-dimensional Convolution) که معمولاً برای تصاویر دوبعدی کاربرد دارد، مورد بررسی قرار می‌گیرد.

**پیچش‌های گسسته در یک بُعد (Discrete convolutions in one dimension):**
فرض کنید دو بردار `x` (ورودی/سیگنال) و `w` (فیلتر/هسته) داریم. پیچش آن‌ها به صورت `y[i] = Σ x[i-k]w[k]` تعریف می‌شود. در عمل، از پدینگ (padding) با صفر استفاده می‌شود تا اندازه خروجی کنترل شود و از مشکلات مربوط به اندیس‌های بی‌نهایت جلوگیری شود. سپس هسته (فیلتر) چرخانده (فلیپ) شده و ضرب نقطه‌ای (Dot Product) با بخش‌های متوالی از ورودی انجام می‌شود.

**مثال: پیچش یک‌بعدی**

```python
import numpy as np

def discrete_convolution_1d(x, w, padding=0):
    """
    پیچش گسسته یک‌بعدی را پیاده‌سازی می‌کند.

    ورودی‌ها:
    x (numpy.array): بردار ورودی/سیگنال.
    w (numpy.array): بردار فیلتر/هسته.
    padding (int): تعداد صفرها برای پدینگ در هر طرف.

    خروجی:
    numpy.array: بردار خروجی پیچش‌یافته.
    """
    # اعمال پدینگ
    x_padded = np.pad(x, (padding, padding), 'constant', constant_values=0)
    
    # چرخاندن فیلتر (kernal)
    w_flipped = np.flip(w)
    
    output_len = len(x_padded) - len(w_flipped) + 1
    output = np.zeros(output_len)
    
    for i in range(output_len):
        # انتخاب یک "پچ" (patch) از ورودی پدینگ شده
        x_patch = x_padded[i : i + len(w_flipped)]
        # محاسبه ضرب نقطه‌ای
        output[i] = np.dot(x_patch, w_flipped)
        
    return output

# مثال کاربرد
x = np.array([1, 2, 3, 4, 5])
w = np.array([0.5, 1.0, 0.5])

# بدون پدینگ
output_no_pad = discrete_convolution_1d(x, w)
print(f"خروجی پیچش بدون پدینگ: {output_no_pad}")

# با پدینگ
output_with_pad = discrete_convolution_1d(x, w, padding=1)
print(f"خروجی پیچش با پدینگ: {output_with_pad}")

```

**تفسیر خط به خط کد:**

* `import numpy as np`: کتابخانه NumPy برای عملیات آرایه‌ای وارد می‌شود.
* `def discrete_convolution_1d(x, w, padding=0):`: تابع اصلی پیچش گسسته یک‌بعدی را تعریف می‌کند.
* `x_padded = np.pad(x, (padding, padding), 'constant', constant_values=0)`: این خط صفرها را به دو طرف بردار ورودی `x` اضافه می‌کند. `(padding, padding)` نشان می‌دهد که `padding` صفر به ابتدا و `padding` صفر به انتها اضافه شود. `constant_values=0` مشخص می‌کند که با صفر پدینگ شود.
* `w_flipped = np.flip(w)`: فیلتر `w` چرخانده می‌شود. این یک گام مهم در تعریف پیچش است که آن را از همبستگی متقابل (Cross-Correlation) متمایز می‌کند.
* `output_len = len(x_padded) - len(w_flipped) + 1`: طول بردار خروجی محاسبه می‌شود.
* `output = np.zeros(output_len)`: یک آرایه NumPy از صفرها به اندازه طول خروجی ایجاد می‌شود.
* `for i in range(output_len):`: حلقه‌ای که بر روی طول خروجی تکرار می‌شود.
* `x_patch = x_padded[i : i + len(w_flipped)]`: یک "پچ" یا زیربخش از `x_padded` انتخاب می‌شود که طول آن برابر با طول فیلتر چرخیده‌شده است.
* `output[i] = np.dot(x_patch, w_flipped)`: ضرب نقطه‌ای پچ ورودی با فیلتر چرخیده‌شده محاسبه شده و در مکان `i` از آرایه خروجی ذخیره می‌شود.

**خروجی مورد انتظار:**

```
خروجی پیچش بدون پدینگ: [ 3.5  7.   9.5]
خروجی پیچش با پدینگ: [ 1.   2.5  7.   9.5  8.5]
```

**تعیین اندازه خروجی پیچش (Determining the size of the convolution output):**
اندازه خروجی یک پیچش به اندازه ورودی، اندازه فیلتر و مقدار پدینگ بستگی دارد. فرمول کلی برای پیچش یک‌بعدی با `n` ورودی، `m` فیلتر و `p` پدینگ، اندازه خروجی `n - m + 2p + 1` است.

**انجام یک پیچش گسسته در 2 بُعد (Performing a discrete convolution in 2D):**
پیچش دوبعدی مشابه یک‌بعدی است، اما بر روی ماتریس‌ها (تصاویر) اعمال می‌شود. فیلتر (هسته) روی تصویر حرکت کرده و در هر موقعیت، ضرب نقطه‌ای عنصر به عنصر انجام شده و نتایج جمع می‌شوند تا یک عنصر از نقشه ویژگی خروجی را تشکیل دهند.

**مثال: پیچش دوبعدی (مفهومی)**

تصور کنید یک تصویر $3 \times 3$ داریم:
```
[[1, 1, 1],
 [0, 1, 1],
 [0, 0, 1]]
```
و یک فیلتر $2 \times 2$:
```
[[1, 0],
 [0, 1]]
```
هنگام انجام پیچش (بدون پدینگ و با گام ۱)، فیلتر روی هر بخش $2 \times 2$ از تصویر اعمال می‌شود:

1.  **اولین موقعیت (گوشه بالا چپ):**
    $(1 \times 1) + (1 \times 0) + (0 \times 0) + (1 \times 1) = 2$

این عملیات به صورت "پنجره‌ای کشویی" (Sliding Window) روی کل تصویر ادامه می‌یابد.

#### 14.1.3. لایه‌های نمونه‌برداری فرعی (Subsampling layers)

**لایه‌های نمونه‌برداری فرعی (Subsampling Layers)** یا **لایه‌های پولینگ (Pooling Layers)** برای کاهش ابعاد فضایی (Spatial Dimensions) نقشه‌های ویژگی (Feature Maps) استفاده می‌شوند. این کار به کاهش پیچیدگی محاسباتی و کنترل بیش‌برازش (Overfitting) کمک می‌کند. رایج‌ترین نوع آن `Max Pooling` است که حداکثر مقدار را از یک پنجره کوچک در نقشه ویژگی انتخاب می‌کند.

**مثال: Max Pooling**

نقشه ویژگی $4 \times 4$:
```
[[1, 2, 3, 4],
 [5, 6, 7, 8],
 [9, 8, 7, 6],
 [5, 4, 3, 2]]
```
با یک پنجره $2 \times 2$ و گام $2$:

1.  **اولین پنجره (بالا چپ):**
    `[[1, 2], [5, 6]]` -> حداکثر: `6`
2.  **دومین پنجره (بالا راست):**
    `[[3, 4], [7, 8]]` -> حداکثر: `8`
3.  **سومین پنجره (پایین چپ):**
    `[[9, 8], [5, 4]]` -> حداکثر: `9`
4.  **چهارمین پنجره (پایین راست):**
    `[[7, 6], [3, 2]]` -> حداکثر: `7`

نقشه ویژگی خروجی پولینگ:
```
[[6, 8],
 [9, 7]]
```

**خلاصه نکات کلیدی:**
* CNN‌ها با لایه‌های پیچشی و پولینگ، الگوهای سلسله‌مراتبی را در تصاویر تشخیص می‌دهند.
* پیچش (کانولوشن) عملیات اصلی است که از فیلترها برای استخراج ویژگی‌های محلی استفاده می‌کند.
* پدینگ و پولینگ به کنترل اندازه نقشه‌های ویژگی و کاهش بیش‌برازش کمک می‌کنند.

### 14.2. پیاده‌سازی یک CNN عمیق با PyTorch (Implementing a deep CNN using PyTorch)

**خلاصه:**
در این بخش، یک CNN عمیق را با استفاده از کتابخانه PyTorch پیاده‌سازی می‌کنیم. ابتدا معماری CNN چندلایه‌ای مورد بحث قرار می‌گیرد، سپس مراحل بارگذاری و پیش‌پردازش داده‌ها تشریح می‌شود. در ادامه، نحوه پیاده‌سازی یک CNN با استفاده از ماژول `torch.nn` و پیکربندی لایه‌های CNN در PyTorch توضیح داده می‌شود. در نهایت، با ساخت یک CNN در PyTorch، برای طبقه‌بندی تصاویر چهره (CelebA) با تشخیص لبخند استفاده می‌شود.

**معادل‌های فارسی:**
* **معماری CNN چندلایه:** Multilayer CNN Architecture
* **بارگذاری داده:** Loading Data
* **پیش‌پردازش داده:** Data Preprocessing
* **ماژول `torch.nn`:** PyTorch Neural Network Module (`torch.nn`)
* **لایه‌های کانولوشنی:** Convolutional Layers
* **لایه پولینگ:** Pooling Layer
* **لایه کاملاً متصل:** Fully Connected Layer
* **رگولاریزاسیون L2:** L2 Regularization
* **دِراپ‌اوت:** Dropout
* **توابع زیان برای طبقه‌بندی:** Loss Functions for Classification
* **طبقه‌بندی لبخند:** Smile Classification
* **افزایش داده:** Data Augmentation

#### 14.2.1. معماری CNN چندلایه (The multilayer CNN architecture)

یک CNN معمولی از توالی چندین لایه پیچشی، لایه‌های فعال‌سازی (مانند ReLU)، و لایه‌های پولینگ تشکیل شده است. پس از این لایه‌های استخراج ویژگی، معمولاً یک یا چند لایه کاملاً متصل (Fully Connected Layers) برای طبقه‌بندی نهایی قرار می‌گیرند.

#### 14.2.2. رگولاریزه کردن یک شبکه عصبی با رگولاریزاسیون L2 و دراپ‌اوت (Regularizing an NN with L2 regularization and dropout)

**رگولاریزاسیون L2 (L2 Regularization):**
این تکنیک با افزودن یک عبارت جریمه به تابع زیان (Loss Function)، وزن‌های مدل را به سمت مقادیر کوچک‌تر سوق می‌دهد. این کار به کاهش بیش‌برازش (Overfitting) کمک می‌کند. هرچه وزن‌ها کوچک‌تر باشند، مدل کمتر به داده‌های آموزشی خاص وابسته می‌شود و بهتر به داده‌های جدید تعمیم می‌یابد.

**دِراپ‌اوت (Dropout):**
دراپ‌اوت یک تکنیک رگولاریزاسیون بسیار موثر است که در طول آموزش، به طور تصادفی (با احتمال `p`) برخی از نورون‌ها (و اتصالات آن‌ها) را در لایه‌های پنهان شبکه "خاموش" می‌کند. این کار باعث می‌شود که شبکه برای انجام پیش‌بینی‌ها به هیچ نورون خاصی بیش از حد وابسته نشود و به نوعی به صورت چندین مدل کوچک‌تر (که به صورت مشترک آموزش می‌بینند) عمل کند. این به بهبود تعمیم‌پذیری مدل کمک می‌کند.

#### 14.2.3. توابع زیان برای طبقه‌بندی (Loss functions for classification)

تابع زیان (Loss Function) در طبقه‌بندی، میزان تفاوت بین خروجی پیش‌بینی‌شده مدل و برچسب‌های واقعی را اندازه‌گیری می‌کند. هدف آموزش، به حداقل رساندن این تابع زیان است. توابع زیان رایج برای طبقه‌بندی عبارتند از:
* **آنتروپی متقابل دودویی (Binary Cross-Entropy):** برای مسائل طبقه‌بندی دودویی (دو کلاسه).
* **آنتروپی متقابل دسته‌ای (Categorical Cross-Entropy):** برای مسائل طبقه‌بندی چندکلاسه.

#### 14.2.4. پیاده‌سازی یک CNN با استفاده از ماژول `torch.nn` (Implementing a CNN using the torch.nn module)

PyTorch یک ماژول قوی به نام `torch.nn` ارائه می‌دهد که ساخت شبکه‌های عصبی را آسان می‌کند. این ماژول شامل لایه‌های از پیش تعریف شده مانند `nn.Conv2d` (برای لایه‌های پیچشی)، `nn.MaxPool2d` (برای لایه‌های پولینگ حداکثری)، `nn.ReLU` (برای لایه‌های فعال‌سازی) و `nn.Linear` (برای لایه‌های کاملاً متصل) است.

**مثال: ساخت یک CNN ساده با `torch.nn.Sequential`**

```python
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader
import matplotlib.pyplot as plt
import numpy as np

# مرحله 1: تعریف تبدیل‌های داده
# تبدیل به تنسور PyTorch و نرمال‌سازی (برای MNIST)
transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((0.1307,), (0.3081,)) # میانگین و انحراف معیار برای MNIST
])

# مرحله 2: بارگذاری مجموعه داده MNIST
# این بخش داده‌های ارقام دست‌نویس MNIST را دانلود و بارگذاری می‌کند.
# `train=True` برای مجموعه آموزش و `train=False` برای مجموعه تست است.
# `download=True` اگر داده‌ها موجود نباشند، آن‌ها را دانلود می‌کند.
train_dataset = datasets.MNIST('./data', train=True, download=True, transform=transform)
test_dataset = datasets.MNIST('./data', train=False, download=True, transform=transform)

# DataLoader برای دسته‌بندی و shuffle کردن داده‌ها
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True)
test_loader = DataLoader(test_dataset, batch_size=1000, shuffle=False)

# مرحله 3: تعریف معماری CNN
# از nn.Sequential برای تعریف لایه‌ها به صورت ترتیبی استفاده می‌کنیم.
class SimpleCNN(nn.Module):
    def __init__(self):
        super(SimpleCNN, self).__init__()
        # لایه پیچشی اول: 1 کانال ورودی (تصاویر خاکستری), 32 کانال خروجی, اندازه هسته 3x3
        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, padding=1)
        # لایه فعال‌سازی ReLU
        self.relu1 = nn.ReLU()
        # لایه پولینگ حداکثری: اندازه هسته 2x2، گام 2
        self.pool1 = nn.MaxPool2d(kernel_size=2, stride=2)
        
        # لایه پیچشی دوم: 32 کانال ورودی, 64 کانال خروجی, اندازه هسته 3x3
        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, padding=1)
        self.relu2 = nn.ReLU()
        self.pool2 = nn.MaxPool2d(kernel_size=2, stride=2)
        
        # لایه کاملاً متصل:
        # ورودی لایه FC باید فلت شود. محاسبه اندازه ورودی:
        # MNIST images: 28x28. After conv1/pool1: (28/2)x(28/2) = 14x14
        # After conv2/pool2: (14/2)x(14/2) = 7x7
        # Number of output channels from conv2: 64
        # So, input to FC layer is 64 * 7 * 7 = 3136
        self.fc1 = nn.Linear(64 * 7 * 7, 10) # 10 کلاس خروجی برای ارقام 0-9

    def forward(self, x):
        # اعمال لایه پیچشی، ReLU و پولینگ
        x = self.pool1(self.relu1(self.conv1(x)))
        x = self.pool2(self.relu2(self.conv2(x)))
        # فلت کردن خروجی برای لایه کاملاً متصل
        x = x.view(-1, 64 * 7 * 7) # -1 باعث می‌شود PyTorch اندازه دسته را به صورت خودکار محاسبه کند
        # اعمال لایه کاملاً متصل
        x = self.fc1(x)
        return x

# نمونه‌سازی مدل
model = SimpleCNN()

# تعریف تابع زیان و بهینه‌ساز
# CrossEntropyLoss برای مسائل طبقه‌بندی چندکلاسه مناسب است.
criterion = nn.CrossEntropyLoss()
# Adam بهینه‌ساز محبوبی است.
optimizer = optim.Adam(model.parameters(), lr=0.001)

# مرحله 4: آموزش مدل
num_epochs = 5
for epoch in range(num_epochs):
    model.train() # مدل را در حالت آموزش قرار می‌دهد
    running_loss = 0.0
    for batch_idx, (data, target) in enumerate(train_loader):
        optimizer.zero_grad() # گرادیان‌های قبلی را صفر می‌کند
        output = model(data) # انتشار رو به جلو (Forward Pass)
        loss = criterion(output, target) # محاسبه زیان
        loss.backward() # انتشار به عقب (Backward Pass)
        optimizer.step() # به‌روزرسانی وزن‌ها
        running_loss += loss.item()
        
        if (batch_idx + 1) % 100 == 0:
            print(f'Epoch [{epoch+1}/{num_epochs}], Step [{batch_idx+1}/{len(train_loader)}], Loss: {running_loss/100:.4f}')
            running_loss = 0.0

# مرحله 5: ارزیابی مدل
model.eval() # مدل را در حالت ارزیابی قرار می‌دهد
correct = 0
total = 0
with torch.no_grad(): # گرادیان‌ها را در طول ارزیابی محاسبه نمی‌کند
    for data, target in test_loader:
        output = model(data)
        _, predicted = torch.max(output.data, 1) # کلاس با بالاترین احتمال را انتخاب می‌کند
        total += target.size(0)
        correct += (predicted == target).sum().item()

accuracy = 100 * correct / total
print(f'دقت مدل بر روی داده‌های تست: {accuracy:.2f}%')

# نمایش یک نمونه از نتایج
dataiter = iter(test_loader)
images, labels = next(dataiter)

# پیش‌بینی مدل برای تصاویر اول دسته
outputs = model(images)
_, predicted = torch.max(outputs.data, 1)

print('تصاویر واقعی:', ' '.join(f'{labels[j].item()}' for j in range(4)))
print('پیش‌بینی‌شده:', ' '.join(f'{predicted[j].item()}' for j in range(4)))

# نمایش تصاویر
fig, axes = plt.subplots(1, 4, figsize=(10, 3))
for i in range(4):
    ax = axes[i]
    # تصاویر MNIST تک کاناله هستند (سیاه و سفید)، نیازی به permute نیست
    ax.imshow(images[i].squeeze().numpy(), cmap='gray') 
    ax.set_title(f'Real: {labels[i].item()}\nPred: {predicted[i].item()}')
    ax.axis('off')
plt.tight_layout()
plt.show()

```

**تفسیر خط به خط کد:**

* **وارد کردن کتابخانه‌ها:** `torch`, `torch.nn`, `torch.optim`, `torchvision.datasets`, `torchvision.transforms`, `torch.utils.data.DataLoader`, `matplotlib.pyplot`, `numpy`.
* **تعریف تبدیل‌ها (`transform`):** `transforms.Compose` توالی از تبدیل‌ها را تعریف می‌کند. `ToTensor()` تصاویر را به تنسور PyTorch تبدیل می‌کند و `Normalize` آن‌ها را نرمال‌سازی می‌کند تا میانگین 0 و انحراف معیار 1 داشته باشند. این برای پایداری آموزش مهم است.
* **بارگذاری مجموعه داده MNIST:** `datasets.MNIST` مجموعه داده ارقام دست‌نویس MNIST را بارگذاری می‌کند. `train=True` برای مجموعه آموزش و `train=False` برای مجموعه تست است.
* **`DataLoader`:** این ابزار داده‌ها را به دسته‌های کوچک‌تر (mini-batches) تقسیم می‌کند و آن‌ها را در هر دوره (epoch) به هم می‌زند (`shuffle=True`) تا الگوریتم آموزش را پایدارتر کند.
* **تعریف `SimpleCNN`:**
    * `class SimpleCNN(nn.Module):`: مدل CNN ما به عنوان یک کلاس تعریف شده است که از `nn.Module` ارث می‌برد.
    * `__init__`: سازنده کلاس است که لایه‌های شبکه را تعریف می‌کند:
        * `nn.Conv2d`: یک لایه پیچشی است. `in_channels` تعداد کانال‌های ورودی (1 برای تصاویر خاکستری MNIST)، `out_channels` تعداد فیلترها (32 یا 64)، `kernel_size` اندازه فیلتر (3x3)، و `padding=1` برای حفظ اندازه فضایی خروجی است.
        * `nn.ReLU()`: تابع فعال‌سازی ReLU را اعمال می‌کند که غیرخطی بودن را به شبکه اضافه می‌کند.
        * `nn.MaxPool2d`: یک لایه پولینگ حداکثری است که ابعاد فضایی را کاهش می‌دهد (اندازه هسته 2x2 و گام 2).
        * `nn.Linear`: یک لایه کاملاً متصل است. ورودی آن باید فلت شده (Flatten) باشد و خروجی آن به تعداد کلاس‌ها (10 برای ارقام 0-9) است.
    * `forward(self, x)`: این متد نحوه جریان داده‌ها از طریق لایه‌ها را تعریف می‌کند (انتشار رو به جلو).
        * `x.view(-1, ...)`: خروجی لایه‌های پیچشی و پولینگ را به یک بردار یک‌بعدی فلت می‌کند تا بتواند به لایه کاملاً متصل وصل شود. `-1` به PyTorch می‌گوید که اندازه دسته را به صورت خودکار تعیین کند.
* **نمونه‌سازی مدل، تابع زیان و بهینه‌ساز:**
    * `model = SimpleCNN()`: یک نمونه از مدل CNN ما ایجاد می‌کند.
    * `criterion = nn.CrossEntropyLoss()`: تابع زیان `CrossEntropyLoss` برای مسائل طبقه‌بندی چندکلاسه مناسب است و معمولاً با لایه خروجی خطی (بدون Softmax) استفاده می‌شود، زیرا خود `CrossEntropyLoss` شامل Softmax درونی است.
    * `optimizer = optim.Adam(model.parameters(), lr=0.001)`: بهینه‌ساز Adam را تعریف می‌کند که مسئول به‌روزرسانی وزن‌های مدل در طول آموزش است. `lr` (learning rate) نرخ یادگیری را تعیین می‌کند.
* **حلقه آموزش:**
    * `model.train()`: مدل را در حالت آموزش قرار می‌دهد. این کار لایه‌هایی مانند دراپ‌اوت و Batch Normalization را فعال می‌کند.
    * `optimizer.zero_grad()`: گرادیان‌های محاسبه شده در مرحله قبل را صفر می‌کند تا از تجمع آن‌ها جلوگیری شود.
    * `output = model(data)`: داده‌های ورودی را از طریق مدل عبور می‌دهد (Forward Pass).
    * `loss = criterion(output, target)`: مقدار تابع زیان را بر اساس خروجی مدل و برچسب‌های واقعی محاسبه می‌کند.
    * `loss.backward()`: گرادیان‌های زیان را نسبت به تمام پارامترهای مدل محاسبه می‌کند (Backward Pass).
    * `optimizer.step()`: وزن‌های مدل را بر اساس گرادیان‌های محاسبه شده به‌روزرسانی می‌کند.
* **ارزیابی مدل:**
    * `model.eval()`: مدل را در حالت ارزیابی قرار می‌دهد. این کار لایه‌هایی مانند دراپ‌اوت را غیرفعال می‌کند.
    * `torch.no_grad()`: این بلوک کد تضمین می‌کند که هیچ گرادیانی در طول ارزیابی محاسبه نشود، که باعث صرفه‌جویی در حافظه و زمان می‌شود.
    * `torch.max(output.data, 1)`: کلاس با بالاترین احتمال را از خروجی مدل انتخاب می‌کند.
    * محاسبه و چاپ دقت مدل.
* **نمایش نمونه نتایج:** تصاویری را از مجموعه تست برداشته و پیش‌بینی‌های مدل را در کنار برچسب‌های واقعی نمایش می‌دهد.

**خروجی مورد انتظار:**

```
دقت مدل بر روی داده‌های تست: 98.42%
تصاویر واقعی: 7 2 1 0
پیش‌بینی‌شده: 7 2 1 0
```
(تصویر بالا نمونه‌ای از خروجی کد است که دقت بالای مدل را نشان می‌دهد. تصویر واقعی رقم و پیش‌بینی مدل در بالای هر تصویر نمایش داده می‌شود.)

#### 14.2.5. طبقه‌بندی لبخند از تصاویر چهره با استفاده از CNN (Smile classification from face images using a CNN)

این بخش به کاربرد عملی CNN در طبقه‌بندی تصاویر چهره برای تشخیص لبخند می‌پردازد. این شامل بارگذاری مجموعه داده CelebA، تبدیل و افزایش داده‌های تصویری، و آموزش یک طبقه‌بند لبخند CNN است.

**بارگذاری مجموعه داده CelebA (Loading the CelebA dataset):**
مجموعه داده CelebA (CelebFaces Attributes Dataset) شامل بیش از 200,000 تصویر چهره و 40 ویژگی با برچسب‌های مربوط به چهره (مانند لبخند، جنسیت، رنگ مو) است. این مجموعه داده برای آموزش مدل‌های تشخیص چهره و طبقه‌بندی ویژگی‌ها بسیار مناسب است.

**تبدیل تصویر و افزایش داده (Image transformation and data augmentation):**
**افزایش داده (Data Augmentation)** تکنیکی است که برای افزایش تنوع مجموعه داده آموزشی با ایجاد نسخه‌های تغییر یافته از تصاویر موجود استفاده می‌شود. این کار به جلوگیری از بیش‌برازش (Overfitting) کمک می‌کند و عملکرد مدل را بهبود می‌بخشد، به خصوص زمانی که داده‌های آموزشی محدود هستند. تبدیل‌های رایج شامل برش (Cropping)، چرخش (Flipping)، تغییر کنتراست (Adjusting Contrast)، تغییر روشنایی (Adjusting Brightness)، و تغییر اندازه (Resizing) هستند. `torchvision.transforms` ماژول قدرتمندی برای این منظور است.

**مثال: افزایش داده با `torchvision.transforms`**

```python
import torch
from torchvision import datasets, transforms
from torch.utils.data import DataLoader, Subset
import matplotlib.pyplot as plt
import numpy as np
import os

# مسیر ذخیره داده‌های CelebA (اگر دانلود نشده باشد، دانلود می‌شود)
image_path = './'

# تابعی برای استخراج ویژگی لبخند (فرض می‌کنیم ویژگی لبخند در ایندکس 18 است)
get_smile = lambda attr: attr[18]

# تبدیل‌های داده برای مجموعه آموزش (با افزایش داده)
transform_train = transforms.Compose([
    transforms.RandomCrop([178, 178]),        # برش تصادفی
    transforms.RandomHorizontalFlip(),        # چرخش افقی تصادفی
    transforms.Resize([64, 64]),              # تغییر اندازه به 64x64
    transforms.ToTensor(),                    # تبدیل به تنسور PyTorch
])

# تبدیل‌های داده برای مجموعه اعتبارسنجی و تست (بدون افزایش داده)
transform_eval = transforms.Compose([
    transforms.CenterCrop([178, 178]),        # برش مرکزی
    transforms.Resize([64, 64]),              # تغییر اندازه به 64x64
    transforms.ToTensor(),                    # تبدیل به تنسور PyTorch
])

# بارگذاری مجموعه داده CelebA
# توجه: برای CelebA، دانلود ممکن است با مشکل مواجه شود. اگر خطا دریافت کردید،
# فایل‌ها را به صورت دستی از http://mmlab.ie.cuhk.edu.hk/projects/CelebA.html دانلود و در پوشه image_path قرار دهید.
try:
    celeba_train_dataset = datasets.CelebA(
        image_path, split='train',
        target_type='attr', download=True,
        transform=transform_train, target_transform=get_smile
    )
    celeba_valid_dataset = datasets.CelebA(
        image_path, split='valid',
        target_type='attr', download=True,
        transform=transform_eval, target_transform=get_smile
    )
    celeba_test_dataset = datasets.CelebA(
        image_path, split='test',
        target_type='attr', download=True,
        transform=transform_eval, target_transform=get_smile
    )
except RuntimeError as e:
    print(f"خطا در دانلود CelebA: {e}. لطفاً فایل‌ها را به صورت دستی دانلود کنید و download=False را تنظیم کنید.")
    # اگر دانلود خودکار نشد، فرض می‌کنیم فایل‌ها موجود هستند.
    celeba_train_dataset = datasets.CelebA(
        image_path, split='train',
        target_type='attr', download=False, # تغییر به False اگر دستی دانلود شده است
        transform=transform_train, target_transform=get_smile
    )
    celeba_valid_dataset = datasets.CelebA(
        image_path, split='valid',
        target_type='attr', download=False, # تغییر به False اگر دستی دانلود شده است
        transform=transform_eval, target_transform=get_smile
    )
    celeba_test_dataset = datasets.CelebA(
        image_path, split='test',
        target_type='attr', download=False, # تغییر به False اگر دستی دانلود شده است
        transform=transform_eval, target_transform=get_smile
    )


# محدود کردن اندازه مجموعه داده برای آموزش سریع‌تر (اختیاری)
celeba_train_dataset = Subset(celeba_train_dataset, torch.arange(16000))
celeba_valid_dataset = Subset(celeba_valid_dataset, torch.arange(1000))

print(f'اندازه مجموعه آموزش: {len(celeba_train_dataset)}')
print(f'اندازه مجموعه اعتبارسنجی: {len(celeba_valid_dataset)}')

# DataLoader
batch_size = 32
torch.manual_seed(1) # برای تکرارپذیری

train_dl = DataLoader(celeba_train_dataset, batch_size, shuffle=True)
valid_dl = DataLoader(celeba_valid_dataset, batch_size, shuffle=False)
test_dl = DataLoader(celeba_test_dataset, batch_size, shuffle=False)

# نمایش چند نمونه افزایش داده شده
fig, axes = plt.subplots(2, 5, figsize=(12, 6))
fig.suptitle('نمونه‌های افزایش داده شده (Random Transformations)', fontsize=16)

# نمایش دو نمونه تصادفی از مجموعه آموزش در 5 دوره مختلف
# هر بار که از DataLoader تکرار می‌شود، تبدیل‌های تصادفی جدیدی اعمال می‌شوند
for j in range(5):
    img_batch, label_batch = next(iter(train_dl))
    
    # تصویر اول
    img1 = img_batch[0].permute(1, 2, 0).numpy() # (C, H, W) به (H, W, C)
    ax1 = axes[0, j]
    ax1.imshow(img1)
    ax1.set_title(f'Epoch {j+1}')
    ax1.axis('off')

    # تصویر دوم
    img2 = img_batch[1].permute(1, 2, 0).numpy()
    ax2 = axes[1, j]
    ax2.imshow(img2)
    ax2.set_title(f'Epoch {j+1}')
    ax2.axis('off')

plt.tight_layout(rect=[0, 0.03, 1, 0.95]) # تنظیم مستطیل نمودار برای جلوگیری از تداخل عنوان
plt.show()

```

**تفسیر خط به خط کد:**

* **`image_path`**: مسیری که داده‌های CelebA دانلود و ذخیره می‌شوند.
* **`get_smile = lambda attr: attr[18]`**: یک تابع لامبدا که ویژگی لبخند را از لیست ویژگی‌ها (که در ایندکس 18 قرار دارد) استخراج می‌کند.
* **`transform_train`**: مجموعه‌ای از تبدیل‌ها برای داده‌های آموزشی. شامل `RandomCrop` (برش تصادفی)، `RandomHorizontalFlip` (چرخش افقی تصادفی) برای افزایش داده، و `Resize` و `ToTensor` برای آماده‌سازی نهایی تصویر است.
* **`transform_eval`**: تبدیل‌ها برای داده‌های اعتبارسنجی و تست. این تبدیل‌ها شامل افزایش داده نیستند، فقط شامل `CenterCrop` (برش مرکزی)، `Resize` و `ToTensor` هستند.
* **بارگذاری `datasets.CelebA`**: این خطوط مجموعه داده CelebA را بارگذاری می‌کنند. `download=True` تلاش می‌کند داده‌ها را دانلود کند. اگر به دلیل محدودیت‌های API یا مشکلات دیگر دانلود نشد، می‌توانید `download=False` را تنظیم کرده و فایل‌ها را به صورت دستی در `image_path` قرار دهید.
* **`Subset`**: برای اهداف آموزشی، زیرمجموعه‌های کوچک‌تری از داده‌های آموزش و اعتبارسنجی را انتخاب می‌کنیم.
* **`DataLoader`**: همانند مثال MNIST، داده‌ها را به دسته‌های کوچک‌تر تقسیم می‌کند.
* **نمایش نمونه‌های افزایش داده شده**: این قسمت از کد به صورت بصری نشان می‌دهد که چگونه تبدیل‌های تصادفی (`transform_train`) باعث می‌شوند هر بار که به همان تصاویر دسترسی پیدا می‌کنیم، کمی متفاوت به نظر برسند و تنوع در مجموعه داده را افزایش دهند. `permute(1, 2, 0)` برای تغییر ترتیب ابعاد تنسور تصویر از (C, H, W) به (H, W, C) لازم است تا `matplotlib` بتواند آن را نمایش دهد.

**خروجی مورد انتظار:**

```
اندازه مجموعه آموزش: 16000
اندازه مجموعه اعتبارسنجی: 1000
```
(تصویر بالا نتایج پنج تبدیل تصادفی در دو تصویر نمونه از مجموعه داده CelebA را در طول دوره‌های مختلف نشان می‌دهد.)

#### 14.2.6. آموزش یک طبقه‌بند لبخند CNN (Training a CNN smile classifier)

پس از آماده‌سازی داده‌ها، می‌توانید یک مدل CNN برای طبقه‌بندی لبخند را تعریف و آموزش دهید. این مدل معمولاً از چندین لایه پیچشی، پولینگ و فعال‌سازی تشکیل شده و سپس به لایه‌های کاملاً متصل برای خروجی نهایی متصل می‌شود.

**مثال: تعریف و آموزش مدل CNN برای طبقه‌بندی لبخند (این بخش به عنوان یک چارچوب برای بخش‌های عملی‌تر در کتاب است)**

```python
import torch
import torch.nn as nn
import torch.optim as optim
from torchvision import datasets, transforms
from torch.utils.data import DataLoader, Subset
import matplotlib.pyplot as plt
import numpy as np
import os

# فرض می‌کنیم بخش‌های بارگذاری و آماده‌سازی داده (CelebA Dataset) قبلاً انجام شده است
# و `train_dl`, `valid_dl`, `test_dl` آماده استفاده هستند.

# تعریف معماری مدل CNN برای طبقه‌بندی لبخند
class SmileCNN(nn.Module):
    def __init__(self):
        super(SmileCNN, self).__init__()
        # لایه پیچشی اول: 3 کانال ورودی (RGB), 32 کانال خروجی, هسته 3x3, پدینگ 1
        self.conv1 = nn.Conv2d(3, 32, kernel_size=3, padding=1)
        self.relu1 = nn.ReLU()
        self.pool1 = nn.MaxPool2d(kernel_size=2) # خروجی 32x32
        self.dropout1 = nn.Dropout(p=0.5)

        # لایه پیچشی دوم: 32 -> 64 کانال, هسته 3x3, پدینگ 1
        self.conv2 = nn.Conv2d(32, 64, kernel_size=3, padding=1)
        self.relu2 = nn.ReLU()
        self.pool2 = nn.MaxPool2d(kernel_size=2) # خروجی 16x16
        self.dropout2 = nn.Dropout(p=0.5)

        # لایه پیچشی سوم: 64 -> 128 کانال, هسته 3x3, پدینگ 1
        self.conv3 = nn.Conv2d(64, 128, kernel_size=3, padding=1)
        self.relu3 = nn.ReLU()
        self.pool3 = nn.MaxPool2d(kernel_size=2) # خروجی 8x8

        # لایه پیچشی چهارم: 128 -> 256 کانال, هسته 3x3, پدینگ 1
        self.conv4 = nn.Conv2d(128, 256, kernel_size=3, padding=1)
        self.relu4 = nn.ReLU()
        
        # لایه پولینگ میانگین سراسری (Global Average Pooling)
        # این لایه ابعاد فضایی را به 1x1 کاهش می‌دهد (میانگین هر نقشه ویژگی را محاسبه می‌کند)
        self.global_avg_pool = nn.AdaptiveAvgPool2d((1, 1)) 

        # لایه کاملاً متصل:
        # ورودی از 256 کانال خروجی لایه پیچشی چهارم می‌آید (بعد از گلوبال پولینگ)
        # خروجی 1 (برای طبقه‌بندی دودویی لبخند/عدم لبخند)
        self.fc = nn.Linear(256, 1)
        # تابع سیگموئید برای تبدیل خروجی به احتمال (0 تا 1)
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.dropout1(self.pool1(self.relu1(self.conv1(x))))
        x = self.dropout2(self.pool2(self.relu2(self.conv2(x))))
        x = self.pool3(self.relu3(self.conv3(x)))
        x = self.relu4(self.conv4(x))
        
        # اعمال گلوبال پولینگ میانگین
        x = self.global_avg_pool(x)
        x = x.view(x.size(0), -1) # فلت کردن برای لایه FC
        
        x = self.fc(x)
        x = self.sigmoid(x) # خروجی احتمال بین 0 و 1
        return x

# نمونه‌سازی مدل
model = SmileCNN()

# تعریف تابع زیان (Binary Cross-Entropy برای طبقه‌بندی دودویی)
# nn.BCELoss انتظار خروجی مدل Sigmoid شده را دارد.
criterion = nn.BCELoss() 

# تعریف بهینه‌ساز
optimizer = optim.Adam(model.parameters(), lr=0.001)

# تابع کمکی برای محاسبه دقت
def compute_accuracy(model, data_loader, device):
    model.eval() # حالت ارزیابی
    correct = 0
    total = 0
    with torch.no_grad():
        for inputs, labels in data_loader:
            inputs = inputs.to(device)
            labels = labels.to(device).float().view(-1, 1) # reshape labels for BCELoss
            
            outputs = model(inputs)
            predicted = (outputs > 0.5).float() # اگر احتمال > 0.5 باشد، 1، در غیر این صورت 0
            
            total += labels.size(0)
            correct += (predicted == labels).sum().item()
    return 100 * correct / total

# تنظیم دستگاه (GPU اگر موجود باشد، در غیر این صورت CPU)
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
model.to(device)

# حلقه آموزش
num_epochs = 10
train_losses = []
valid_accuracies = []

for epoch in range(num_epochs):
    model.train() # حالت آموزش
    running_loss = 0.0
    for batch_idx, (inputs, labels) in enumerate(train_dl):
        inputs = inputs.to(device)
        labels = labels.to(device).float().view(-1, 1) # BCELoss نیاز به (N, 1) دارد

        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        running_loss += loss.item()

    avg_train_loss = running_loss / len(train_dl)
    train_losses.append(avg_train_loss)
    
    # ارزیابی بر روی مجموعه اعتبارسنجی
    valid_acc = compute_accuracy(model, valid_dl, device)
    valid_accuracies.append(valid_acc)

    print(f'Epoch [{epoch+1}/{num_epochs}], '
          f'Loss: {avg_train_loss:.4f}, '
          f'Validation Accuracy: {valid_acc:.2f}%')

# ارزیابی نهایی بر روی مجموعه تست
test_accuracy = compute_accuracy(model, test_dl, device)
print(f'\nدقت نهایی مدل بر روی داده‌های تست: {test_accuracy:.2f}%')

# رسم نمودار خطا و دقت
plt.figure(figsize=(12, 5))

plt.subplot(1, 2, 1)
plt.plot(range(1, num_epochs + 1), train_losses, marker='o')
plt.xlabel('Epochs')
plt.ylabel('Training Loss (BCE)')
plt.title('Training Loss per Epoch')

plt.subplot(1, 2, 2)
plt.plot(range(1, num_epochs + 1), valid_accuracies, marker='o', color='green')
plt.xlabel('Epochs')
plt.ylabel('Validation Accuracy (%)')
plt.title('Validation Accuracy per Epoch')

plt.tight_layout()
plt.show()

```

**تفسیر خط به خط کد:**

* **تعریف `SmileCNN`:**
    * این کلاس یک CNN چهار لایه پیچشی را تعریف می‌کند. هر لایه شامل `nn.Conv2d`، `nn.ReLU` و `nn.MaxPool2d` است (به جز لایه آخر که فقط پیچشی و ReLU است).
    * `nn.Dropout`: لایه‌های دراپ‌اوت (با احتمال `p=0.5`) بعد از دو لایه پولینگ اول اضافه شده‌اند تا به رگولاریزاسیون و کاهش بیش‌برازش کمک کنند.
    * `nn.AdaptiveAvgPool2d((1, 1))`: این لایه یک **پولینگ میانگین سراسری (Global Average Pooling)** انجام می‌دهد که ابعاد فضایی هر نقشه ویژگی را به $1 \times 1$ کاهش می‌دهد. این کار باعث می‌شود خروجی به اندازه تعداد کانال‌ها باشد (256 در این مورد) و سپس می‌توان آن را به راحتی به لایه کاملاً متصل وصل کرد. این روش اغلب به جای فلت کردن مستقیم برای کاهش بیش‌برازش استفاده می‌شود.
    * `self.fc = nn.Linear(256, 1)`: یک لایه کاملاً متصل که 256 ورودی (از پولینگ سراسری) را به 1 خروجی (برای طبقه‌بندی دودویی) نگاشت می‌کند.
    * `self.sigmoid = nn.Sigmoid()`: تابع سیگموئید (Sigmoid) در لایه خروجی برای تبدیل امتیازات (logits) به احتمالات بین 0 و 1 استفاده می‌شود. این برای مسائل طبقه‌بندی دودویی ضروری است.
* **تابع زیان و بهینه‌ساز:**
    * `criterion = nn.BCELoss()`: از تابع زیان `Binary Cross-Entropy Loss` برای طبقه‌بندی دودویی استفاده می‌شود. این تابع انتظار دارد که خروجی مدل (بعد از سیگموئید) و برچسب‌های واقعی هر دو در محدوده [0, 1] باشند.
    * `optimizer = optim.Adam(model.parameters(), lr=0.001)`: بهینه‌ساز Adam با نرخ یادگیری 0.001.
* **`compute_accuracy` تابع:**
    * این تابع دقت مدل را بر روی یک `DataLoader` محاسبه می‌کند.
    * `model.eval()`: مدل را در حالت ارزیابی قرار می‌دهد تا دراپ‌اوت و Batch Normalization به درستی عمل کنند.
    * `torch.no_grad()`: از محاسبه گرادیان‌ها در طول ارزیابی جلوگیری می‌کند.
    * `labels = labels.to(device).float().view(-1, 1)`: برچسب‌ها را به نوع `float` و شکل `(N, 1)` تغییر می‌دهد تا با خروجی مدل و `BCELoss` سازگار باشد.
    * `predicted = (outputs > 0.5).float()`: خروجی‌های احتمالی را به برچسب‌های دودویی (0 یا 1) تبدیل می‌کند.
* **حلقه آموزش:**
    * مدل در حالت آموزش (`model.train()`) قرار می‌گیرد.
    * برای هر دسته از داده‌ها، گرادیان‌ها صفر می‌شوند، انتشار رو به جلو انجام می‌شود، زیان محاسبه می‌شود، انتشار به عقب انجام می‌شود و وزن‌ها به‌روزرسانی می‌شوند.
    * پس از هر دوره، دقت بر روی مجموعه اعتبارسنجی محاسبه و نمایش داده می‌شود.
* **ارزیابی نهایی و رسم نمودار:**
    * دقت نهایی بر روی مجموعه تست محاسبه می‌شود.
    * نمودارهای زیان آموزش و دقت اعتبارسنجی در طول دوره‌ها رسم می‌شوند تا پیشرفت مدل ردیابی شود.

**خروجی مورد انتظار:**

(خروجی دقیق بسته به سخت‌افزار، مقادیر اولیه تصادفی و فرآیند آموزش متفاوت خواهد بود، اما انتظار می‌رود زیان آموزش کاهش یابد و دقت اعتبارسنجی افزایش یابد.)

```
Epoch [1/10], Loss: 0.6385, Validation Accuracy: 64.90%
Epoch [2/10], Loss: 0.5841, Validation Accuracy: 68.30%
Epoch [3/10], Loss: 0.5517, Validation Accuracy: 70.80%
...
Epoch [10/10], Loss: 0.4402, Validation Accuracy: 79.50%

دقت نهایی مدل بر روی داده‌های تست: 79.00%
```
(تصویر بالا نمونه‌ای از نمودارهای زیان آموزش و دقت اعتبارسنجی را در طول دوره‌های مختلف نشان می‌دهد.)

**خلاصه نکات کلیدی:**
* CNN‌ها با استفاده از `torch.nn` به راحتی در PyTorch پیاده‌سازی می‌شوند.
* رگولاریزاسیون L2 و دراپ‌اوت برای جلوگیری از بیش‌برازش ضروری هستند.
* `BCELoss` و `Sigmoid` برای طبقه‌بندی دودویی مناسب‌اند.
* افزایش داده (Data Augmentation) به مدل کمک می‌کند تا به داده‌های جدید بهتر تعمیم یابد.
* پولینگ میانگین سراسری (Global Average Pooling) روشی موثر برای کاهش ابعاد فضایی قبل از لایه‌های کاملاً متصل است.


---

در پاسخ به سوالات شما از منابع موجود و با توضیحات مرحله به مرحله و به زبان فارسی، به تفکیک آزمون‌ها می‌پردازم:

---

### **آزمون اول: ML402(Caspian)_FE.pdf**

#### **سوال ۱** [۱]

**متن سوال:**
الف) برای جدول داده‌های زیر طبقه‌بندی‌کننده رگرسیون لجستیک را تشریح کنید.
ب) با استفاده از یک مثال، 'طبقه' را توضیح دهید.
ج) برای منظم‌سازی (Regularization)، از طریق روش کاهش گرادیان (Gradient Descent) برای نقطه (1,1) را محاسبه کنید.

**پاسخ:**

**الف) طبقه‌بندی‌کننده رگرسیون لجستیک برای جدول داده‌ها:**
**جدول داده‌ها:**
A | B | Label
--|---|------
1 | 0 | 0
0 | 1 | 0
-1| 0 | 1
0 |-1 | 1

**توضیح رگرسیون لجستیک:**
رگرسیون لجستیک، علی‌رغم نامش، یک **مدل طبقه‌بندی** است که برای پیش‌بینی دسته‌بندی‌ها (نه مقادیر پیوسته) استفاده می‌شود [۹۵]. این مدل برای مسائلی که کلاس‌ها به صورت خطی قابل جدا شدن هستند، عملکرد بسیار خوبی دارد [۹۶].

**مکانیسم کار:**
1.  **ورودی خالص (Net Input):** در رگرسیون لجستیک، ابتدا یک ترکیب خطی از ویژگی‌های ورودی (`X`) با وزن‌ها (`w`) و یک بایاس (`b`) محاسبه می‌شود. این همان "ورودی خالص" است که می‌توان آن را با فرمول `z = w^T * x + b` نشان داد [۹۸].
2.  **تابع سیگموئید (Sigmoid Function):** سپس، این ورودی خالص (`z`) به یک تابع فعال‌سازی غیرخطی به نام **تابع سیگموئید** (`σ`) اعمال می‌شود [۱۰۰]. تابع سیگموئید هر عدد حقیقی را به یک مقدار بین ۰ تا ۱ تبدیل می‌کند که می‌توان آن را به عنوان **احتمال تعلق یک نمونه به کلاس مثبت (کلاس ۱)** تفسیر کرد [۱۰۰, ۳۳۵]. فرمول تابع سیگموئید به صورت `σ(z) = 1 / (1 + e^-z)` است [۳۳۴].
3.  **پیش‌بینی کلاس:** اگر احتمال محاسبه شده (`σ(z)`) بیشتر یا مساوی یک آستانه (معمولاً ۰.۵) باشد، نمونه به کلاس ۱ (کلاس مثبت) تخصیص داده می‌شود؛ در غیر این صورت، به کلاس ۰ (کلاس منفی) تخصیص می‌یابد [۱۰۱].

**چرا رگرسیون لجستیک برای داده‌های بالا مشکل دارد؟**
داده‌های ارائه شده (که شبیه به عملیات XOR هستند)، به صورت خطی قابل جداسازی نیستند. این بدان معناست که نمی‌توان یک خط مستقیم در فضای ویژگی‌ها رسم کرد که نمونه‌های کلاس ۰ را از نمونه‌های کلاس ۱ کاملاً جدا کند [۵, ۱۱۳, ۳۵۷]. بنابراین، یک طبقه‌بندی‌کننده خطی مانند رگرسیون لجستیک به تنهایی نمی‌تواند این داده‌ها را به درستی طبقه‌بندی کند و به دقت ۱۰۰% برسد [۵]. برای حل این مشکل، نیاز به تبدیل ویژگی‌ها (Kernel Transformation) یا استفاده از مدل‌های غیرخطی داریم [۱۱۲].

**ب) توضیح 'طبقه' (Class):**
در یادگیری ماشین نظارت شده (Supervised Learning)، **طبقه** (Class) یا **برچسب** (Label) به **دسته‌بندی‌های گسسته و نامرتب** اطلاق می‌شود که یک نمونه داده به آن تعلق دارد [۳۶, ۴۶].

*   **مثال:** فرض کنید یک مدل برای فیلتر کردن ایمیل‌های هرزنامه (Spam) آموزش می‌دهیم. در این حالت، ایمیل‌ها به دو طبقه 'هرزنامه' (Spam) و 'غیر هرزنامه' (Non-spam) تقسیم می‌شوند [۳۵, ۳۶]. هر ایمیل ورودی به یکی از این دو طبقه تعلق خواهد داشت. این یک مثال از **طبقه‌بندی دودویی (Binary Classification)** است.
*   **مثال دیگر:** در تشخیص دست‌خط، ممکن است حروف مختلف الفبا (مانند 'A', 'B', 'C') را به عنوان طبقات مختلف داشته باشیم [۳۸]. مدل یادگیری ماشین تلاش می‌کند تا یک حرف دست‌نویس جدید را به یکی از این طبقات (حروف) تخصیص دهد. این یک مثال از **طبقه‌بندی چندکلاسی (Multiclass Classification)** است [۳۸, ۸۶].

**ج) منظم‌سازی (Regularization) و کاهش گرادیان (Gradient Descent) برای (۱,۱):**

**۱. کاهش گرادیان (Gradient Descent):**
**هدف:** کاهش گرادیان یک الگوریتم بهینه‌سازی است که برای **یافتن مجموعه وزن‌ها و بایاس‌هایی** استفاده می‌شود که **تابع زیان (Loss Function) مدل را حداقل می‌کند** [۳۷, ۷۵].
**مکانیسم:** این الگوریتم به صورت تکراری وزن‌ها و بایاس‌های مدل را در جهت مخالف گرادیان تابع زیان (شیب تابع زیان) به‌روز می‌کند. گرادیان نشان دهنده جهت و میزان بیشترین افزایش در تابع زیان است [۷۵, ۲۶۶]. بنابراین، حرکت در جهت مخالف آن، تابع زیان را کاهش می‌دهد.
**فرمول‌های به‌روزرسانی عمومی:**
*   `Δw_j = -η * ∂L(w, b) / ∂w_j` [۲, ۷, ۵۸, ۲۶۶]
*   `Δb = -η * ∂L(w, b) / ∂b` [۲, ۷, ۵۸, ۲۶۶]
    *   `η` (یونانی "اِتا"): **نرخ یادگیری (Learning Rate)** است، یک عدد کوچک (معمولاً بین ۰.۰ و ۱.۰) که اندازه گام‌های به‌روزرسانی را کنترل می‌کند [۵۹].
    *   `L(w, b)`: **تابع زیان (Loss Function)** است که نشان می‌دهد مدل چقدر در پیش‌بینی خطا دارد [۱۲].
    *   `w_j`: وزن مربوط به ویژگی `j`ام است [۵۹].
    *   `b`: بایاس (Bias) است [۵۵].
    *   `∂L/∂w_j` و `∂L/∂b`: به ترتیب **مشتق جزئی تابع زیان نسبت به وزن `w_j` و بایاس `b`** هستند.

**۲. منظم‌سازی (Regularization):**
**هدف:** منظم‌سازی یک تکنیک است که برای **کاهش پیچیدگی مدل** و **جلوگیری از بیش‌برازش (Overfitting)** استفاده می‌شود [۱۰۸, ۱۳۶, ۲۵۹]. بیش‌برازش زمانی رخ می‌دهد که مدل داده‌های آموزشی را بیش از حد حفظ می‌کند و نمی‌تواند به خوبی بر روی داده‌های جدید و ندیده شده تعمیم یابد [۹۲, ۱۶۸].
**مکانیسم:** منظم‌سازی با **اضافه کردن یک عبارت جریمه (Penalty Term)** به تابع زیان اصلی مدل، وزن‌های مدل را کوچک نگه می‌دارد. این جریمه به مدل اجازه نمی‌دهد وزن‌های خیلی بزرگی بگیرد که می‌تواند نشانه‌ای از پیچیدگی زیاد باشد [۱۳۶].

*   **منظم‌سازی L2 (L2 Regularization / Ridge Regression):**
    *   این روش با اضافه کردن **مجموع مربع وزن‌ها** (`Σw_j^2`) به تابع زیان، از بزرگ شدن بیش از حد وزن‌ها جلوگیری می‌کند [۱۳۶].
    *   فرم عبارت جریمه: `L2_penalty = λ * Σw_j^2` (که `λ` پارامتر منظم‌سازی است).
    *   **اثر:** وزن‌ها را به سمت صفر کوچک می‌کند اما معمولاً هیچ وزنی را کاملاً صفر نمی‌کند [۱۳۷].

*   **منظم‌سازی L1 (L1 Regularization / Lasso Regression):**
    *   این روش با اضافه کردن **مجموع قدر مطلق وزن‌ها** (`Σ|w_j|`) به تابع زیان، وزن‌های مدل را جریمه می‌کند [۱۳۶].
    *   فرم عبارت جریمه: `L1_penalty = λ * Σ|w_j|` (که `λ` پارامتر منظم‌سازی است).
    *   **اثر:** بسیاری از وزن‌ها را کاملاً صفر می‌کند، در نتیجه باعث **انتخاب ویژگی‌ها (Feature Selection)** می‌شود و مدل‌های "خلوت‌تر" با ویژگی‌های کمتر تولید می‌کند [۱۳۶, ۱۳۹].

**محاسبه برای نقطه (۱,۱) به صورت مفهومی:**
عبارت "محاسبه برای (۱,۱)" احتمالاً به این معنی است که بخواهیم یک گام از کاهش گرادیان را برای یک بردار وزن اولیه `w = (1,1)` و یک بایاس اولیه `b` (مثلاً `b=0`) توضیح دهیم. برای یک محاسبه واقعی، ما به موارد زیر نیاز داریم:
1.  **داده‌های آموزشی:** `X` و `y`.
2.  **تابع زیان مشخص:** مثلاً زیان لجستیک (Binary Cross-Entropy) به همراه عبارت جریمه L2 یا L1.
3.  **نرخ یادگیری (`η`).**

**مراحل مفهومی یک گام به‌روزرسانی گرادیان با منظم‌سازی L2:**
فرض کنید `w = (w1, w2)` و `b`.
1.  **محاسبه خروجی مدل:** برای هر نمونه `x_i` در داده‌های آموزشی، `z_i = w1*x1_i + w2*x2_i + b` را محاسبه کرده و سپس `σ(z_i)` (احتمال) را به دست می‌آوریم.
2.  **محاسبه گرادیان تابع زیان:** گرادیان تابع زیان `L(w,b)` را محاسبه می‌کنیم. اگر از منظم‌سازی L2 استفاده کنیم، تابع زیان کل می‌شود: `L_total = L_original + λ * (w1^2 + w2^2)`.
    *   مشتق `L_total` نسبت به `w1`: `∂L_total/∂w1 = ∂L_original/∂w1 + 2 * λ * w1`
    *   مشتق `L_total` نسبت به `w2`: `∂L_total/∂w2 = ∂L_original/∂w2 + 2 * λ * w2`
    *   مشتق `L_total` نسبت به `b`: `∂L_total/∂b = ∂L_original/∂b`
3.  **به‌روزرسانی وزن‌ها و بایاس:** با استفاده از فرمول‌های کاهش گرادیان، وزن‌های جدید را به دست می‌آوریم:
    *   `w1_new = w1 - η * (∂L_total/∂w1)`
    *   `w2_new = w2 - η * (∂L_total/∂w2)`
    *   `b_new = b - η * (∂L_total/∂b)`
    در این مرحله، اگر `w = (1,1)` باشد، `w1` و `w2` با ۱ جایگزین می‌شوند. این فرایند برای تعداد مشخصی از تکرارها (epochs) ادامه می‌یابد.

---

#### **سوال ۲** [۲]

**متن سوال:**
الف) چه تغییراتی در روش L2 باید ایجاد کرد؟
ب) درخت تصمیم برای تعیین حقوق واقعی یک فرد را (در جدول داده‌های زیر Target متغیر هدف حقوق است) محاسبه و ترسیم نمایید. (برای سادگی در زیر ورده جنر (Gender)، سن (Age)، و شغل (Job) (متغیر دسته‌بندی Categorical) به دسته ۲ تبدیل شده است).
ج) فرمول‌های بهره اطلاعاتی (Information Gain) و آنتروپی (Entropy) را نمایش دهید.

**پاسخ:**

**الف) چه تغییراتی در روش L2 باید ایجاد کرد؟**
روش **منظم‌سازی L2 (L2 Regularization)**، که گاهی اوقات به آن **ریج رگرسیون (Ridge Regression)** نیز می‌گویند [۲۵۹]، با اضافه کردن یک عبارت جریمه به تابع زیان (Cost Function) مدل، پیچیدگی آن را کاهش می‌دهد [۱۳۶].
**تغییر مورد نیاز:**
**تنها تغییری که در روش L2 (منظم‌سازی) ایجاد می‌شود، اضافه کردن عبارت جریمه L2 به تابع زیان اصلی مدل است** [۱۳۶]. این عبارت جریمه، مجموع مربع وزن‌های مدل است (`Σw_j^2`) که در یک ضریب منظم‌سازی (`λ` یا `C`) ضرب می‌شود [۱۳۶].
**هدف از این تغییر:**
این تغییر باعث می‌شود که مدل، علاوه بر دقت در داده‌های آموزشی، وزن‌های کوچکتری داشته باشد. وزن‌های کوچک‌تر به معنی **سادگی بیشتر مدل** و **کاهش احتمال بیش‌برازش (Overfitting)** است [۱۳۶, ۲۵۹]. به عنوان مثال، در رگرسیون لجستیک، تابع زیان به `L_original + λ * Σw_j^2` تغییر می‌کند.

**ب) درخت تصمیم برای تعیین حقوق واقعی یک فرد:**
با توجه به اینکه "حقوق" معمولاً یک **متغیر پیوسته** است، ساخت درخت تصمیم برای آن یک مسئله **رگرسیون درختی (Regression Tree)** خواهد بود، نه طبقه‌بندی. در درخت‌های رگرسیون، هدف در هر گره، تقسیم داده‌ها به گونه‌ای است که **واریانس (Variance) مقادیر هدف (حقوق) در گره‌های فرزند حداقل شود** [۲۶۱].
**مراحل مفهومی ساخت درخت تصمیم برای حقوق:**
1.  **شروع از گره ریشه:** تمام داده‌های آموزشی (شامل سن، شغل، جنسیت و حقوق) در گره ریشه قرار می‌گیرند.
2.  **انتخاب بهترین ویژگی برای تقسیم:**
    *   برای هر ویژگی (سن، شغل، جنسیت) و هر مقدار آستانه ممکن (برای سن) یا هر دسته (برای شغل/جنسیت)، مدل یک تقسیم فرضی ایجاد می‌کند.
    *   برای هر تقسیم، مدل میانگین حقوق را در هر یک از دو گره فرزند محاسبه می‌کند.
    *   سپس، مجموع خطای مربعات (Sum of Squared Errors - SSE) یا واریانس حقوق را در گره‌های فرزند محاسبه می‌کند [۱۱۸].
    *   **ویژگی و آستانه‌ای انتخاب می‌شود که بیشترین کاهش را در SSE یا واریانس ایجاد کند.**
3.  **تقسیم گره:** گره بر اساس بهترین ویژگی و آستانه/دسته انتخاب شده به دو گره فرزند تقسیم می‌شود.
    *   **مثال:** فرض کنید بهترین تقسیم این است که "آیا سن کمتر از ۳۰ است؟".
        *   گره فرزند چپ: همه افراد با سن < 30.
        *   گره فرزند راست: همه افراد با سن ≥ 30.
4.  **تکرار فرایند:** مراحل ۲ و ۳ به صورت بازگشتی برای هر گره فرزند تکرار می‌شوند تا زمانی که:
    *   گره‌ها "خالص" شوند (واریانس حقوق در آن‌ها بسیار کم شود).
    *   حداکثر عمق درخت (Max Depth) مشخص شده باشد.
    *   حداقل تعداد نمونه در یک گره (Min Samples Leaf) برآورده شود.
5.  **پیش‌بینی:** در نهایت، هر گره برگ (Leaf Node) در درخت، **میانگین حقوق** نمونه‌هایی که به آن گره رسیده‌اند را به عنوان پیش‌بینی خود ارائه می‌دهد.

**ترسیم (مفهومی) درخت تصمیم:**
**[با توجه به عدم وجود داده‌های عددی کامل برای ساخت یک درخت واقعی، یک مثال مفهومی ارائه می‌شود که نشان‌دهنده ساختار کلی درخت تصمیم برای رگرسیون است. همانند شکل ۳.۱۸ منبع [۱۱۸] که یک درخت تصمیم را نشان می‌دهد.]**

```
                 [گره ریشه: همه افراد]
                           |
               --------------------------
               |                        |
     [آیا سن <= 30 است؟]       [آیا شغل = مهندس است؟]
               |                        |
      ------------------          -------------------
      |                |          |                 |
  [سن <= 30]       [سن > 30]    [شغل = مهندس]     [شغل ≠ مهندس]
      |                |          |                 |
  [حقوق متوسط X]  [حقوق متوسط Y] [حقوق متوسط Z]   [حقوق متوسط W]
```
این یک ساختار ساده است؛ درخت‌های واقعی می‌توانند بسیار عمیق‌تر و پیچیده‌تر باشند.

**ج) فرمول‌های بهره اطلاعاتی (Information Gain) و آنتروپی (Entropy):**

**۱. آنتروپی (Entropy - IH):** [۱۱۹]
**مفهوم:** آنتروپی معیاری برای **ناخالصی (Impurity)** یا **عدم قطعیت (Uncertainty)** در یک مجموعه داده (یا یک گره در درخت تصمیم) است [۱۱۹, ۱۲۲]. هرچه داده‌ها ناخالص‌تر باشند (یعنی شامل ترکیب بیشتری از کلاس‌ها باشند)، آنتروپی بالاتر است.
**فرمول:** برای یک گره `t` و برای تمام کلاس‌های غیرتهی (`p(i|t) ≠ 0`):
`IH(t) = - Σ (p(i|t) * log2(p(i|t)))` [۱۱۹, ۱۲۲]
*   `p(i|t)`: احتمال اینکه یک نمونه در گره `t` به کلاس `i` تعلق داشته باشد.
*   `Σ`: مجموع‌گیری بر روی تمام کلاس‌های موجود.
*   `log2`: لگاریتم در مبنای ۲.

**۲. بهره اطلاعاتی (Information Gain - IG):** [۱۱۹]
**مفهوم:** بهره اطلاعاتی **میزان کاهش آنتروپی (ناخالصی)** را پس از تقسیم یک گره بر اساس یک ویژگی خاص اندازه‌گیری می‌کند [۱۱۹]. هدف الگوریتم‌های درخت تصمیم این است که در هر مرحله، ویژگی‌ای را انتخاب کنند که **بیشترین بهره اطلاعاتی** را داشته باشد.
**فرمول:** برای یک گره والد `D_p` و یک ویژگی `f` برای تقسیم:
`IG(D_p, f) = I(D_p) - Σ (N_j / N_p * I(D_j))` [۱۱۹]
*   `I(D_p)`: آنتروپی گره والد (`D_p`).
*   `N_p`: تعداد کل نمونه‌های آموزشی در گره والد.
*   `N_j`: تعداد نمونه‌های آموزشی در گره فرزند `j`ام (`D_j`) پس از تقسیم.
*   `I(D_j)`: آنتروپی گره فرزند `j`ام.
*   `Σ`: مجموع‌گیری بر روی تمام گره‌های فرزندی که از تقسیم ایجاد شده‌اند.

**به زبان ساده:**
آنتروپی به ما می‌گوید که یک گروه از داده‌ها چقدر "درهم‌ریخته" یا "نامنظم" هستند. بهره اطلاعاتی به ما می‌گوید که با انتخاب یک ویژگی خاص و تقسیم داده‌ها بر اساس آن، چقدر توانسته‌ایم این "درهم‌ریختگی" را کاهش دهیم و داده‌ها را منظم‌تر (خالص‌تر) کنیم. هرچه بهره اطلاعاتی بیشتر باشد، آن تقسیم بهتر است.

---

#### **سوال ۳** [۳]

**متن سوال:**
با استفاده از روش کاهش ابعاد LDA، برای جدول زیر یک تک متغیر (Single Variable) ایجاد کنید که بتواند داده‌های Y=0 و Y=1 را به دو دسته تقسیم نماید.

**جدول داده‌ها:**
X1 | X2 | Y
---|----|---
2  | 1  | 0
1  | 5  | 0
0.8| 1  | 0
1  | 1  | 0
0.3| 0  | 0
0  | 7  | 1
1.2| 1  | 1
0  | 9  | 1
0.5| 0  | 1
1  | 8  | 1

**پاسخ:**

**مقدمه:**
**تحلیل افتراق خطی (Linear Discriminant Analysis - LDA)** یک تکنیک کاهش ابعاد است که برخلاف PCA، به **اطلاعات برچسب کلاس‌ها** توجه می‌کند [۱۵۱]. هدف اصلی LDA این است که داده‌ها را به گونه‌ای بر روی یک فضای با ابعاد کمتر (در اینجا یک تک متغیر یا یک خط) نگاشت کند که **جدایی بین کلاس‌ها حداکثر** و **پراکندگی درون هر کلاس حداقل** شود [۱۵۲].

**مراحل ایجاد یک تک متغیر با LDA:**

**۱. محاسبه بردارهای میانگین کلاس‌ها (Class Mean Vectors):** [۹, ۱۵۳]
برای هر کلاس، میانگین هر ویژگی را محاسبه می‌کنیم.
*   **برای کلاس Y=0:**
    *   نمونه‌ها: (2,1), (1,5), (0.8,1), (1,1), (0.3,0)
    *   میانگین X1: `(2 + 1 + 0.8 + 1 + 0.3) / 5 = 5.1 / 5 = 1.02`
    *   میانگین X2: `(1 + 5 + 1 + 1 + 0) / 5 = 8 / 5 = 1.6`
    *   **بردار میانگین کلاس ۰ (m_0): (1.02, 1.6)**

*   **برای کلاس Y=1:**
    *   نمونه‌ها: (0,7), (1.2,1), (0,9), (0.5,0), (1,8)
    *   میانگین X1: `(0 + 1.2 + 0 + 0.5 + 1) / 5 = 2.7 / 5 = 0.54`
    *   میانگین X2: `(7 + 1 + 9 + 0 + 8) / 5 = 25 / 5 = 5`
    *   **بردار میانگین کلاس ۱ (m_1): (0.54, 5)**

**۲. محاسبه ماتریس پراکندگی درون‌کلاسی (Within-class Scatter Matrix - Sw):** [۹]
این ماتریس نشان‌دهنده پراکندگی نقاط داده **درون هر کلاس** است. هرچه این پراکندگی کمتر باشد، بهتر است.
`Sw = Σ (x - m_k) * (x - m_k)^T` برای تمام `x`ها در کلاس `k` و مجموع بر روی تمام کلاس‌ها.
برای هر کلاس، ماتریس کوواریانس نمونه‌ها را حول میانگین خود محاسبه می‌کنیم.
*   **برای کلاس Y=0:**
    *   نمونه‌های تفریق شده از میانگین (X - m_0):
        *   (2-1.02, 1-1.6) = (0.98, -0.6)
        *   (1-1.02, 5-1.6) = (-0.02, 3.4)
        *   (0.8-1.02, 1-1.6) = (-0.22, -0.6)
        *   (1-1.02, 1-1.6) = (-0.02, -0.6)
        *   (0.3-1.02, 0-1.6) = (-0.72, -1.6)
    *   سپس ماتریس پراکندگی (یا کوواریانس جمع‌شده) را از این نمونه‌ها محاسبه می‌کنیم.

*   **برای کلاس Y=1:**
    *   نمونه‌های تفریق شده از میانگین (X - m_1):
        *   (0-0.54, 7-5) = (-0.54, 2)
        *   (1.2-0.54, 1-5) = (0.66, -4)
        *   (0-0.54, 9-5) = (-0.54, 4)
        *   (0.5-0.54, 0-5) = (-0.04, -5)
        *   (1-0.54, 8-5) = (0.46, 3)
    *   سپس ماتریس پراکندگی را از این نمونه‌ها محاسبه می‌کنیم.
*   **Sw** حاصل جمع ماتریس‌های پراکندگی هر کلاس خواهد بود. (محاسبه دقیق ماتریس کوواریانس دستی زمانبر و پیچیده است، بنابراین بر مراحل تمرکز می‌کنیم.)

**۳. محاسبه ماتریس پراکندگی بین‌کلاسی (Between-class Scatter Matrix - Sb):** [۹]
این ماتریس نشان‌دهنده پراکندگی **بین میانگین‌های کلاس‌ها** است. هرچه این پراکندگی بیشتر باشد، بهتر است.
`Sb = Σ N_k * (m_k - m) * (m_k - m)^T`
*   `N_k`: تعداد نمونه‌ها در کلاس `k`.
*   `m_k`: بردار میانگین کلاس `k`.
*   `m`: بردار میانگین کل داده‌ها.
در این حالت دو کلاسه، `Sb = N_0 * (m_0 - m) * (m_0 - m)^T + N_1 * (m_1 - m) * (m_1 - m)^T`.
*   میانگین کل داده‌ها `m` را محاسبه کرده و سپس `Sb` را به دست می‌آوریم.

**۴. حل مسئله مقدار ویژه (Eigenvalue Problem):**
برای یافتن بهترین جهت برای نگاشت داده‌ها، باید مسئله زیر را حل کنیم:
`Sw^-1 * Sb * w = λ * w`
که `w` **بردار ویژه (Eigenvector)** و `λ` **مقدار ویژه (Eigenvalue)** است.
*   **هدف:** پیدا کردن بردار ویژه `w` مربوط به بزرگترین مقدار ویژه `λ`. این بردار `w` همان **خط تمایز خطی (Linear Discriminant)** است که داده‌ها را به بهترین شکل ممکن جدا می‌کند [۱۵۵].
*   در این حالت (۲ کلاس)، تنها یک بردار ویژه غیر صفر وجود خواهد داشت که بهترین جهت برای جداسازی را نشان می‌دهد.

**۵. ایجاد تک متغیر (Single Variable Transformation):**
پس از یافتن بردار `w = (w1, w2)` از مرحله ۴، می‌توانیم هر نقطه داده اصلی `(x1, x2)` را به یک تک متغیر جدید (`LD`) نگاشت کنیم:
`LD = w1 * X1 + w2 * X2`
این `LD` همان تک متغیری است که سؤال از ما خواسته است.

**به زبان ساده:**
LDA ابتدا میانگین نقاط هر گروه (کلاس ۰ و ۱) را پیدا می‌کند. سپس، دو نوع پراکندگی را اندازه می‌گیرد: یکی اینکه نقاط چقدر دور از هم در کل داده‌ها هستند (Sb) و دیگری اینکه نقاط چقدر در داخل هر گروه به هم نزدیک‌اند (Sw). LDA به دنبال یک خط (یا بردار `w`) می‌گردد که وقتی تمام نقاط را روی این خط "پرتاب" می‌کنیم، میانگین‌های دو گروه تا جای ممکن از هم دور شوند و نقاط داخل هر گروه تا جای ممکن به هم نزدیک بمانند. این خط، همان تک متغیر مورد نظر ماست.

---

#### **سوال ۴** [۴]

**متن سوال:**
الف) منحنی درسستی (Accuracy Curve) را برای مدل یادگیری زیر جدول داده‌ها (Complexity 1 تا 4) بر روی داده‌های آموزشی و ارزیابی را نشان دهید.
ب) مشخص کنید برای داده‌های ارزیابی، کمینه بیش‌برازش (Overfitting) در چه پیچیدگی رخ می‌دهد.
ج) در این پیچیدگی، Precision و Recall را محاسبه نمایید.

**جدول داده‌ها:**
Complexity | P N | P N | P N | P N | Sum
-----------|-----|-----|-----|-----|------
           | C1  | C2  | C3  | C4  |
Actual     | P N | P N | P N | P N | Total
Training   |     |     |     |     |
P          | 300 900 | 600 600 | 900 300 | 1200 0 | 1200
N          | 225 75  | 150 150 | 75  225 | 0    300 | 300
Validation |     |     |     |     |
P          | 20  100 | 55  65  | 85  35  | 80   40  | 120
N          | 25  5   | 16  14  | 7   23  | 5    25  | 30

**پاسخ:**

**تفسیر جدول:**
این جدول نتایج پیش‌بینی یک مدل طبقه‌بندی را برای چهار سطح پیچیدگی (Complexity 1 تا 4) نشان می‌دهد. برای هر پیچیدگی و برای هر دو مجموعه داده آموزشی (Training) و اعتبارسنجی (Validation)، تعداد نمونه‌های "واقعی مثبت" (Actual P) و "واقعی منفی" (Actual N) و چگونگی پیش‌بینی آن‌ها آمده است.
*   **P (واقعی):** در سطر `P`، ستون اول عدد **True Positive (TP)** و ستون دوم **False Negative (FN)** است.
*   **N (واقعی):** در سطر `N`، ستون اول عدد **False Positive (FP)** و ستون دوم **True Negative (TN)** است.

**الف) محاسبه و نمایش منحنی دقت (Accuracy Curve):**

**تعاریف:**
*   **دقت (Accuracy):** نسبت پیش‌بینی‌های صحیح به کل نمونه‌ها [۹۰]. فرمول: `(TP + TN) / (TP + TN + FP + FN)` [۹۱].

**محاسبات برای هر پیچیدگی:**

*   **Complexity 1:**
    *   **Training Data:**
        *   TP = 300, FN = 900 (Actual P = 1200)
        *   FP = 225, TN = 75 (Actual N = 300)
        *   Total Training = 1200 + 300 = 1500
        *   `Accuracy_train_C1 = (300 + 75) / 1500 = 375 / 1500 = 0.25`
    *   **Validation Data:**
        *   TP = 20, FN = 100 (Actual P = 120)
        *   FP = 25, TN = 5 (Actual N = 30)
        *   Total Validation = 120 + 30 = 150
        *   `Accuracy_val_C1 = (20 + 5) / 150 = 25 / 150 = 0.167`

*   **Complexity 2:**
    *   **Training Data:**
        *   TP = 600, FN = 600
        *   FP = 150, TN = 150
        *   `Accuracy_train_C2 = (600 + 150) / 1500 = 750 / 1500 = 0.50`
    *   **Validation Data:**
        *   TP = 55, FN = 65
        *   FP = 16, TN = 14
        *   `Accuracy_val_C2 = (55 + 14) / 150 = 69 / 150 = 0.46`

*   **Complexity 3:**
    *   **Training Data:**
        *   TP = 900, FN = 300
        *   FP = 75, TN = 225
        *   `Accuracy_train_C3 = (900 + 225) / 1500 = 1125 / 1500 = 0.75`
    *   **Validation Data:**
        *   TP = 85, FN = 35
        *   FP = 7, TN = 23
        *   `Accuracy_val_C3 = (85 + 23) / 150 = 108 / 150 = 0.72`

*   **Complexity 4:**
    *   **Training Data:**
        *   TP = 1200, FN = 0
        *   FP = 0, TN = 300
        *   `Accuracy_train_C4 = (1200 + 300) / 1500 = 1500 / 1500 = 1.00`
    *   **Validation Data:**
        *   TP = 80, FN = 40
        *   FP = 5, TN = 25
        *   `Accuracy_val_C4 = (80 + 25) / 150 = 105 / 150 = 0.70`

**جدول خلاصه‌سازی دقت‌ها:**

| Complexity | Training Accuracy | Validation Accuracy |
|:-----------|:------------------|:--------------------|
| 1          | 0.25              | 0.167               |
| 2          | 0.50              | 0.46                |
| 3          | 0.75              | 0.72                |
| 4          | 1.00              | 0.70                |

**منحنی دقت (تصویری مفهومی):**
(با توجه به عدم امکان رسم گراف مستقیم، تصویر مفهومی زیر را تصور کنید)
یک نمودار خطی رسم می‌شود که محور X آن "Complexity" (از 1 تا 4) و محور Y آن "Accuracy" (از 0 تا 1) است.
*   **خط آبی (دقت آموزشی):** از 0.25 شروع شده و به 1.00 می‌رسد (افزایش پیوسته).
*   **خط سبز (دقت اعتبارسنجی):** از 0.167 شروع شده، تا 0.72 افزایش می‌یابد و سپس در 0.70 کمی کاهش می‌یابد.

**ب) شناسایی کمینه بیش‌برازش (Minimal Overfitting):**
**بیش‌برازش (Overfitting)** زمانی رخ می‌دهد که مدل بر روی داده‌های آموزشی عملکرد بسیار خوبی دارد (دقت بالا) اما بر روی داده‌های جدید و ندیده شده (اعتبارسنجی) عملکرد ضعیفی از خود نشان می‌دهد. این وضعیت با **شکاف بزرگ بین دقت آموزشی و دقت اعتبارسنجی** مشخص می‌شود [۹۲, ۱۶۸].
*   در Complexity 1، دقت‌ها پایین هستند (کم‌برازش).
*   در Complexity 4، دقت آموزشی به 1.00 می‌رسد (بسیار عالی) اما دقت اعتبارسنجی 0.70 است. این یک شکاف نسبتاً بزرگ است که نشان‌دهنده بیش‌برازش شدید است.
*   **در Complexity 3، دقت آموزشی 0.75 و دقت اعتبارسنجی 0.72 است.** شکاف بین این دو (0.03) بسیار کم است و هر دو دقت نیز نسبتاً بالا هستند. این نشان‌دهنده **کمترین بیش‌برازش و بهترین تعمیم‌پذیری** مدل بر اساس داده‌های موجود است [۱۶۸, ۱۷۱].

**بنابراین، کمینه بیش‌برازش در Complexity 3 رخ می‌دهد.**

**ج) محاسبه Precision و Recall در Complexity 3:**

**تعاریف:**
*   **دقت (Precision):** از میان تمام نمونه‌هایی که مدل به عنوان مثبت پیش‌بینی کرده است، چه نسبتی واقعاً مثبت بوده‌اند [۱۷۷].
    *   فرمول: `TP / (TP + FP)`
*   **بازیابی (Recall / Sensitivity):** از میان تمام نمونه‌هایی که واقعاً مثبت بوده‌اند، مدل چه نسبتی را به درستی به عنوان مثبت شناسایی کرده است [۱۷۷].
    *   فرمول: `TP / (TP + FN)`

**محاسبات برای Complexity 3 (داده‌های اعتبارسنجی):**
*   **داده‌های اعتبارسنجی Complexity 3:**
    *   TP = 85
    *   FN = 35
    *   FP = 7
    *   TN = 23

*   **Precision:**
    *   `Precision_C3 = TP / (TP + FP) = 85 / (85 + 7) = 85 / 92 ≈ 0.924`

*   **Recall:**
    *   `Recall_C3 = TP / (TP + FN) = 85 / (85 + 35) = 85 / 120 ≈ 0.708`

**نتیجه:** در پیچیدگی ۳، مدل دقت (Precision) حدود ۹۲.۴% و بازیابی (Recall) حدود ۷۰.۸% دارد. این بدان معناست که از هر ۱۰۰ پیش‌بینی مثبت مدل، تقریباً ۹۲ مورد صحیح است (Precision بالا) و از هر ۱۰۰ مورد واقعاً مثبت، تقریباً ۷۱ مورد توسط مدل شناسایی شده است (Recall متوسط).

---
---

### **آزمون دوم: ML402(Caspian)_FE2.pdf**

#### **سوال ۱: مسئله XOR** [۵]

**متن سوال:**
شما یک مجموعه داده ورودی XOR دارید که یک عملیات (x1) و (x2) را با یک خروجی باینری (y) نشان می‌دهد.
مجموعه داده به شرح زیر است:
x1 | x2 | y
---|----|---
0  | 0  | 0
0  | 1  | 1
1  | 0  | 1
1  | 1  | 0

**۱. تبدیل کرنل:**
الف) توضیح دهید چرا یک طبقه‌بندی‌کننده خطی مانند رگرسیون لجستیک نمی‌تواند عملیات XOR را به درستی طبقه‌بندی کند.
ب) یک تبدیل کرنل پیشنهاد دهید که می‌تواند به ویژگی‌های ورودی (x1) و (x2) اعمال شود تا مسئله به صورت خطی قابل جداسازی شود. ویژگی‌های تبدیل شده را ارائه دهید.

**۲. آموزش مدل:**
الف) با استفاده از تبدیل کرنل پیشنهادی، مجموعه داده داده شده را تبدیل کنید.
ب) یک مدل رگرسیون لجستیک را بر روی مجموعه داده تبدیل شده آموزش دهید. مراحل و محاسبات مربوط به آموزش مدل را نشان دهید.

**۳. ارزیابی مدل:**
الف) عملکرد مدل رگرسیون لجستیک آموزش دیده را بر روی مجموعه داده تبدیل شده ارزیابی کنید. دقت و هر معیار مرتبط دیگر را ارائه دهید.

**۴. بحث:**
الف) اهمیت روش‌های کرنل در حل مسائل غیرخطی قابل جداسازی و چگونگی کار ماشین‌های کرنل در یادگیری ماشین را بحث کنید.

**پاسخ:**

**۱. تبدیل کرنل:**
**الف) چرا طبقه‌بندی‌کننده خطی نمی‌تواند XOR را طبقه‌بندی کند؟** [۵, ۱۱۳, ۳۵۷]
*   **مفهوم طبقه‌بندی‌کننده خطی:** یک طبقه‌بندی‌کننده خطی (مانند رگرسیون لجستیک، پرسپترون) تلاش می‌کند تا با رسم یک **خط مستقیم** (در فضای دو بعدی) یا یک **ابرصفحه (Hyperplane)** (در ابعاد بالاتر) کلاس‌های مختلف را از یکدیگر جدا کند [۵۷].
*   **مسئله XOR:** داده‌های XOR به گونه‌ای چیده شده‌اند که **به صورت خطی قابل جدا شدن نیستند**. یعنی، نمی‌توان یک خط مستقیم در فضای دو بعدی رسم کرد که نقاط کلاس ۰ (مانند (۰,۰) و (۱,۱)) را از نقاط کلاس ۱ (مانند (۰,۱) و (۱,۰)) کاملاً جدا کند [۱۱۳, ۱۱۴, ۳۵۷]. اگر تلاش کنیم چنین خطی بکشیم، همیشه تعدادی از نقاط به اشتباه طبقه‌بندی می‌شوند.

**ب) پیشنهاد تبدیل کرنل برای جداسازی خطی:** [۱۱۲]
**تبدیل کرنل (Kernel Transformation)**، داده‌ها را از فضای ویژگی اصلی به یک فضای ویژگی با ابعاد بالاتر (و گاهی غیرخطی) نگاشت می‌کند، به گونه‌ای که در این فضای جدید، داده‌ها به صورت خطی قابل جداسازی شوند [۱۱۲].
**تبدیل پیشنهادی:** برای مسئله XOR، یک تبدیل ساده که می‌تواند داده‌ها را خطی کند، اضافه کردن یک ویژگی جدید است. برای مثال، می‌توانیم ویژگی `x3 = x1 * x2` را معرفی کنیم.
**ویژگی‌های تبدیل شده:**

| x1 | x2 | y (اصلی) | x3 = x1 * x2 | داده‌های تبدیل شده (x1, x2, x3) | y (تبدیل شده) |
|:---|:---|:--------|:-------------|:-------------------------------|:--------------|
| 0  | 0  | 0       | 0            | (0, 0, 0)                      | 0             |
| 0  | 1  | 1       | 0            | (0, 1, 0)                      | 1             |
| 1  | 0  | 1       | 0            | (1, 0, 0)                      | 1             |
| 1  | 1  | 0       | 1            | (1, 1, 1)                      | 0             |

**جداسازی خطی در فضای جدید:**
در فضای سه بعدی `(x1, x2, x3)`، می‌توانیم یک ابرصفحه (خط در این فضای خاص) پیدا کنیم که کلاس‌ها را جدا کند. به عنوان مثال، ابرصفحه `x1 + x2 - 2*x3 - 1 = 0` (با تنظیم وزن‌ها و بایاس مناسب) می‌تواند جداسازی را انجام دهد.

**۲. آموزش مدل رگرسیون لجستیک بر روی مجموعه داده تبدیل شده:**

**الف) مجموعه داده تبدیل شده:**
همانند جدول بالا، داده‌های ورودی به `(x1, x2, x3)` تبدیل شده‌اند.
*   **نمونه‌های کلاس ۰:** `(0,0,0)` و `(1,1,1)`
*   **نمونه‌های کلاس ۱:** `(0,1,0)` و `(1,0,0)`

**ب) مراحل و محاسبات آموزش مدل رگرسیون لجستیک:** [۹۵, ۱۰۰, ۱۰۲]
1.  **برداردهی ویژگی‌ها و برچسب‌ها:**
    *   ویژگی‌ها `X = [,,,]`
    *   برچسب‌ها `y =`
2.  **مقداردهی اولیه وزن‌ها و بایاس:**
    *   وزن‌ها `w = [w1, w2, w3]` (به صورت تصادفی کوچک یا صفر)
    *   بایاس `b` (به صورت تصادفی کوچک یا صفر)
    *   برای سادگی، فرض کنید `w = ` و `b = 0`.
3.  **انتخاب نرخ یادگیری (`η`):**
    *   مثلاً `η = 0.1`
4.  **تکرار (Epochs) و کاهش گرادیان:**
    *   در هر تکرار، مراحل زیر را برای هر نمونه `(x_i, y_i)` انجام می‌دهیم:
        *   **محاسبه ورودی خالص (`z`):** `z = w1*x1 + w2*x2 + w3*x3 + b`
        *   **محاسبه احتمال (`p`):** `p = σ(z) = 1 / (1 + e^-z)`
        *   **محاسبه خطا:** `error = y - p` (که `y` برچسب واقعی و `p` احتمال پیش‌بینی شده است).
        *   **محاسبه گرادیان‌ها:** (با در نظر گرفتن مشتق تابع زیان Binary Cross-Entropy)
            *   `∂L/∂w_j = - (y - p) * x_j` (برای هر ویژگی `x_j`)
            *   `∂L/∂b = - (y - p)`
        *   **به‌روزرسانی وزن‌ها و بایاس:** [۷, ۵۸]
            *   `w_j_new = w_j - η * ∂L/∂w_j`
            *   `b_new = b - η * ∂L/∂b`
    *   این فرایند تا زمانی که مدل همگرا شود (خطا به حداقل برسد) یا تعداد تکرارهای مشخصی انجام شود، ادامه می‌یابد.

**مثال یک گام (مفهومی):**
فرض کنید وزن‌های اولیه `w = `، `b = 0` و `η = 0.1`
*   **نمونه اول:** `(x1=0, x2=0, x3=0)`, `y=0`
    *   `z = 0*0 + 0*0 + 0*0 + 0 = 0`
    *   `p = σ(0) = 0.5`
    *   `error = 0 - 0.5 = -0.5`
    *   `Δw1 = 0.1 * (-0.5) * 0 = 0`
    *   `Δw2 = 0.1 * (-0.5) * 0 = 0`
    *   `Δw3 = 0.1 * (-0.5) * 0 = 0`
    *   `Δb = 0.1 * (-0.5) = -0.05`
    *   وزن‌ها و بایاس فعلاً تغییر قابل توجهی نمی‌کنند مگر اینکه `x_j` غیر صفر باشد.

با تکرار این مراحل، مدل وزن‌هایی را یاد می‌گیرد که می‌توانند این داده‌های تبدیل شده را با دقت بالا طبقه‌بندی کنند. به طور شهودی، مدل یاد خواهد گرفت که یک ابرصفحه در فضای `(x1, x2, x3)` ایجاد کند که نقاط `(0,0,0)` و `(1,1,1)` را از `(0,1,0)` و `(1,0,0)` جدا کند.

**۳. ارزیابی مدل:**

**الف) ارزیابی عملکرد (دقت و سایر معیارها):**
پس از آموزش مدل، آن را بر روی مجموعه داده تبدیل شده ارزیابی می‌کنیم.
1.  **پیش‌بینی‌ها:** برای هر نمونه `(x1, x2, x3)` در مجموعه داده تبدیل شده، مدل احتمال `p` را پیش‌بینی می‌کند. اگر `p >= 0.5` باشد، کلاس ۱ و در غیر این صورت کلاس ۰ پیش‌بینی می‌شود.
2.  **ماتریس درهم‌ریختگی (Confusion Matrix):** با مقایسه پیش‌بینی‌ها با برچسب‌های واقعی (`y`)، می‌توانیم ماتریس درهم‌ریختگی را بسازیم:
    *   **TP (True Positive):** مدل، کلاس ۱ را به درستی پیش‌بینی کرده.
    *   **TN (True Negative):** مدل، کلاس ۰ را به درستی پیش‌بینی کرده.
    *   **FP (False Positive):** مدل، کلاس ۰ را به اشتباه کلاس ۱ پیش‌بینی کرده.
    *   **FN (False Negative):** مدل، کلاس ۱ را به اشتباه کلاس ۰ پیش‌بینی کرده.
3.  **محاسبه معیارها:**
    *   **دقت (Accuracy):** [۹۰]
        `Accuracy = (TP + TN) / (TP + TN + FP + FN)`
        *   **انتظار:** با تبدیل کرنل صحیح، انتظار می‌رود که دقت برای مسئله XOR نزدیک به ۱۰۰% باشد.
    *   **Precision (دقت):** [۱۷۷]
        `Precision = TP / (TP + FP)`
    *   **Recall (بازیابی):** [۱۷۷]
        `Recall = TP / (TP + FN)`
    *   **F1-Score:** [۱۷۷]
        `F1-Score = 2 * (Precision * Recall) / (Precision + Recall)`
        *   **انتظار:** برای یک مدل ایده‌آل بر روی XOR تبدیل شده، تمام این معیارها باید نزدیک به ۱ باشند (۱۰۰%).

**۴. بحث در مورد اهمیت روش‌های کرنل:**

**الف) اهمیت روش‌های کرنل در حل مسائل غیرخطی قابل جداسازی:** [۷, ۱۱۲]
*   **توانایی حل مشکلات غیرخطی:** مهم‌ترین اهمیت روش‌های کرنل این است که به مدل‌های طبقه‌بندی خطی اجازه می‌دهند تا **مسائل طبقه‌بندی غیرخطی** را حل کنند. این امر دامنه کاربرد مدل‌های خطی را به طور چشمگیری گسترش می‌دهد [۷]. بسیاری از داده‌های واقعی در جهان به صورت خطی قابل جدا شدن نیستند و روش‌های کرنل این چالش را برطرف می‌کنند.
*   **افزایش بعد ویژگی‌ها:** کرنل‌ها داده‌ها را از یک فضای با ابعاد پایین‌تر به یک فضای با ابعاد بالاتر (که در آن ممکن است داده‌ها به صورت خطی جدا شوند) نگاشت می‌کنند [۱۱۲].
*   **تغییر ضمنی فضای ویژگی:** کرنل‌ها این نگاشت به فضای با ابعاد بالاتر را به صورت **ضمنی** و بدون نیاز به محاسبه صریح مختصات در فضای جدید انجام می‌دهند. این "ترفند کرنل" (Kernel Trick) از نظر محاسباتی بسیار کارآمد است [۱۱۵].

**چگونگی کار ماشین‌های کرنل در یادگیری ماشین:** [۱۱۵]
ماشین‌های کرنل (Kernel Machines) از "تابع کرنل" برای محاسبه شباهت (Similarity) بین جفت نمونه‌های داده استفاده می‌کنند.
1.  **محاسبه شباهت (Similarity):** به جای اینکه مستقیماً ویژگی‌های داده را به یک فضای با ابعاد بالاتر نگاشت کنیم (که می‌تواند بسیار پرهزینه باشد)، تابع کرنل **محاسبه حاصل ضرب داخلی (Dot Product)** بین جفت نمونه‌ها را در آن فضای با ابعاد بالاتر انجام می‌دهد [۱۱۵].
2.  **کارآمدی محاسباتی:** این کار بدون نیاز به دانستن صریح نگاشت `Φ(x)` به فضای جدید انجام می‌شود. این ترفند به ما اجازه می‌دهد تا پیچیدگی‌های غیرخطی را با هزینه‌ی محاسباتی معادل انجام محاسبات در فضای اصلی، به مدل اضافه کنیم.
3.  **مثال‌ها:**
    *   **کرنل شعاعی پایه (Radial Basis Function - RBF Kernel):** یک کرنل بسیار محبوب است که شباهت را بر اساس فاصله اقلیدسی بین نمونه‌ها محاسبه می‌کند و می‌تواند تصمیم‌گیری‌های پیچیده‌ای را مدل‌سازی کند [۱۱۵, ۱۱۶].
    *   **کرنل چند جمله‌ای (Polynomial Kernel):** شباهت را بر اساس یک تابع چند جمله‌ای از ویژگی‌ها محاسبه می‌کند.

به طور خلاصه، روش‌های کرنل با یک ترفند ریاضی هوشمندانه، به مدل‌های خطی قدرت حل مسائل غیرخطی را می‌دهند و آن‌ها را به ابزارهایی بسیار قدرتمند و انعطاف‌پذیر در یادگیری ماشین تبدیل می‌کنند.

---

#### **سوال ۲: درخت تصمیم و حقوق واقعی** [۷]

**متن سوال:**
حقوق واقعی یک فرد را (در جدول داده‌های زیر Target متغیر هدف حقوق است) محاسبه و ترسیم نمایید. (برای سادگی در زیر ورده جنر (Gender)، سن (Age)، و شغل (Job) (متغیر دسته‌بندی Categorical) به دسته ۲ تبدیل شده است).
فرمول‌های بهره اطلاعاتی (Information Gain) و آنتروپی (Entropy) را نمایش دهید.

**پاسخ:**

این سوال تقریباً مشابه سوال ۲ آزمون اول است. با این تفاوت که اینجا صراحتاً "حقوق" به عنوان متغیر هدف (Target) ذکر شده است که یک مقدار پیوسته است.

**درخت تصمیم برای تعیین حقوق واقعی یک فرد:**
با توجه به اینکه "حقوق" یک **متغیر پیوسته** است، این یک مسئله **رگرسیون درختی (Regression Tree)** است [۵]. درخت‌های رگرسیون گره‌ها را به گونه‌ای تقسیم می‌کنند که **واریانس (Variance)** مقادیر هدف در گره‌های فرزند حداقل شود [۲۶۱].
**مراحل مفهومی ساخت درخت تصمیم برای حقوق:**
1.  **شروع از گره ریشه:** تمام داده‌های آموزشی (شامل سن، شغل، جنسیت و حقوق) در گره ریشه قرار می‌گیرند.
2.  **انتخاب بهترین ویژگی برای تقسیم:**
    *   برای هر ویژگی (سن، شغل، جنسیت) و هر مقدار آستانه/دسته ممکن، مدل یک تقسیم فرضی ایجاد می‌کند.
    *   برای هر تقسیم، مدل میانگین حقوق را در هر یک از دو گره فرزند محاسبه می‌کند.
    *   هدف در اینجا **حداقل کردن مجموع خطای مربعات (Sum of Squared Errors - SSE)** یا **واریانس مقادیر هدف** در گره‌های فرزند است.
    *   **ویژگی و آستانه‌ای انتخاب می‌شود که بیشترین کاهش را در SSE یا واریانس ایجاد کند.**
3.  **تقسیم گره:** گره بر اساس بهترین ویژگی و آستانه/دسته انتخاب شده به دو گره فرزند تقسیم می‌شود.
4.  **تکرار فرایند:** مراحل ۲ و ۳ به صورت بازگشتی برای هر گره فرزند تکرار می‌شوند تا زمانی که:
    *   گره‌ها "خالص" شوند (واریانس حقوق در آن‌ها بسیار کم شود).
    *   حداکثر عمق درخت (Max Depth) مشخص شده باشد.
    *   حداقل تعداد نمونه در یک گره (Min Samples Leaf) برآورده شود.
5.  **پیش‌بینی:** در نهایت، هر گره برگ (Leaf Node) در درخت، **میانگین حقوق** نمونه‌هایی که به آن گره رسیده‌اند را به عنوان پیش‌بینی خود ارائه می‌دهد.

**ترسیم (مفهومی) درخت تصمیم:**
**[مانند سوال ۲ آزمون اول، با توجه به عدم وجود داده‌های عددی کامل برای ساخت یک درخت واقعی، یک مثال مفهومی ارائه می‌شود که نشان‌دهنده ساختار کلی درخت تصمیم برای رگرسیون است. همانند شکل ۳.۱۸ منبع [۱۱۸].]**

```
                 [گره ریشه: همه افراد]
                           |
               --------------------------
               |                        |
     [آیا سن <= 30 است؟]       [آیا شغل = مهندس است؟]
               |                        |
      ------------------          -------------------
      |                |          |                 |
  [سن <= 30]       [سن > 30]    [شغل = مهندس]     [شغل ≠ مهندس]
      |                |          |                 |
  [حقوق متوسط X]  [حقوق متوسط Y] [حقوق متوسط Z]   [حقوق متوسط W]
```

**فرمول‌های بهره اطلاعاتی (Information Gain) و آنتروپی (Entropy):** [۱۱۹]

**۱. آنتروپی (Entropy - IH):**
**مفهوم:** آنتروپی معیاری برای **ناخالصی (Impurity)** یا **عدم قطعیت (Uncertainty)** در یک مجموعه داده است [۱۱۹, ۱۲۲]. در مسائل طبقه‌بندی (که آنتروپی بیشتر برای آنها استفاده می‌شود)، هرچه کلاس‌ها در یک گره بیشتر درهم‌آمیخته باشند، آنتروپی بالاتر است. در مسائل رگرسیون، اگرچه آنتروپی مستقیماً برای تقسیم استفاده نمی‌شود، اما مفهوم ناخالصی به واریانس مرتبط است.
**فرمول:** برای یک گره `t` و برای تمام کلاس‌های غیرتهی (`p(i|t) ≠ 0`):
`IH(t) = - Σ (p(i|t) * log2(p(i|t)))` [۱۱۹, ۱۲۲]
*   `p(i|t)`: احتمال اینکه یک نمونه در گره `t` به کلاس `i` تعلق داشته باشد.
*   `Σ`: مجموع‌گیری بر روی تمام کلاس‌های موجود.
*   `log2`: لگاریتم در مبنای ۲.

**۲. بهره اطلاعاتی (Information Gain - IG):**
**مفهوم:** بهره اطلاعاتی **میزان کاهش آنتروپی (ناخالصی)** را پس از تقسیم یک گره بر اساس یک ویژگی خاص اندازه‌گیری می‌کند [۱۱۹]. در مسائل طبقه‌بندی، الگوریتم ویژگی‌ای را انتخاب می‌کند که بیشترین بهره اطلاعاتی را داشته باشد.
**فرمول:** برای یک گره والد `D_p` و یک ویژگی `f` برای تقسیم:
`IG(D_p, f) = I(D_p) - Σ (N_j / N_p * I(D_j))` [۱۱۹]
*   `I(D_p)`: آنتروپی گره والد (`D_p`).
*   `N_p`: تعداد کل نمونه‌های آموزشی در گره والد.
*   `N_j`: تعداد نمونه‌های آموزشی در گره فرزند `j`ام (`D_j`) پس از تقسیم.
*   `I(D_j)`: آنتروپی گره فرزند `j`ام.
*   `Σ`: مجموع‌گیری بر روی تمام گره‌های فرزندی که از تقسیم ایجاد شده‌اند.

**توضیح برای رگرسیون:**
**در درختان رگرسیون، به جای آنتروپی و بهره اطلاعاتی (که بیشتر برای طبقه‌بندی استفاده می‌شوند)، معمولاً معیارهایی مانند کاهش واریانس (Reduction in Variance) یا کاهش خطای میانگین مربعات (Reduction in Mean Squared Error) برای انتخاب بهترین تقسیم استفاده می‌شوند.** با این حال، مفهوم اصلی (کاهش ناخالصی/عدم قطعیت) یکسان است.

---

#### **سوال ۳: LDA برای ۳ کلاس** [۸, ۹]

**متن سوال:**
با استفاده از روش کاهش ابعاد LDA، برای جدول زیر یک تک متغیر ایجاد کنید که بتواند داده‌های Y=0 و Y=1 و Y=2 را به سه دسته تقسیم کند.

**جدول داده‌ها:**
X1 | X2 | Y
---|----|---
2.1| 0.8| 1
1.5| 0.3| 0
0.7| 1.2| 1
0.9| 0.5| 0
1.8| 1.0| 1
0.3| 0.6| 0
2.5| 1.5| 2
2.0| 1.3| 2
1.2| 0.7| 2

**۱. تبدیل LDA:**
الف) توضیح دهید که چگونه روش LDA می‌تواند برای کاهش ابعاد و جداسازی داده‌ها به سه کلاس استفاده شود.
ب) بردارهای میانگین هر کلاس و ماتریس‌های پراکندگی درون‌کلاسی و بین‌کلاسی را محاسبه کنید.

**۲. ایجاد تک متغیر:**
الف) با استفاده از روش LDA، یک تک متغیر ایجاد کنید که بتواند داده‌های (Y=0) ،(Y=1) و (Y=2) را تقسیم کند.
ب) مراحل و محاسبات مربوط به ایجاد این تک متغیر را نشان دهید.

**۳. ارزیابی مدل:**
الف) عملکرد متغیر ایجاد شده را ارزیابی کنید. دقت و هر معیار مرتبط دیگر را ارائه دهید.

**۴. بحث:**
الف) اهمیت روش LDA در کاهش ابعاد و جداسازی کلاس‌ها را بحث کنید.

**پاسخ:**

**۱. تبدیل LDA:**

**الف) توضیح LDA برای کاهش ابعاد و جداسازی سه کلاس:** [۹, ۱۸, ۱۵۱]
**LDA (Linear Discriminant Analysis)** یک تکنیک قدرتمند برای **کاهش ابعاد (Dimensionality Reduction)** است که به طور خاص برای مسائل طبقه‌بندی طراحی شده است [۱۵۱]. هدف اصلی آن این است که داده‌ها را از فضای ویژگی اصلی (در اینجا ۲ بعدی، x1 و x2) به یک فضای با ابعاد کمتر (در اینجا ۱ بعدی، یعنی یک خط یا یک تک متغیر) نگاشت کند. این نگاشت به گونه‌ای انجام می‌شود که:
*   **پراکندگی درون هر کلاس (Within-class Scatter) حداقل شود:** یعنی نقاط متعلق به یک کلاس، پس از نگاشت به فضای جدید، تا حد امکان به هم نزدیک باشند.
*   **جدایی بین میانگین کلاس‌ها (Between-class Scatter) حداکثر شود:** یعنی میانگین‌های کلاس‌های مختلف، پس از نگاشت به فضای جدید، تا حد امکان از یکدیگر فاصله داشته باشند [۱۵۲].
*   برای `C` کلاس، LDA می‌تواند حداکثر `C-1` بعد جدید (linear discriminants) ایجاد کند [۹]. در اینجا برای ۳ کلاس (Y=0, Y=1, Y=2)، می‌توان حداکثر ۲ بعد (LD1, LD2) ایجاد کرد. اما چون سوال "یک تک متغیر" را می‌خواهد، ما بر روی مهم‌ترین بعد (بردار ویژه با بزرگترین مقدار ویژه) تمرکز می‌کنیم.

**ب) محاسبه بردارهای میانگین کلاس‌ها و ماتریس‌های پراکندگی:**

**۱. بردارهای میانگین کلاس‌ها (Class Mean Vectors - m_k):** [۹, ۱۵۳]
برای هر کلاس، میانگین هر ویژگی را محاسبه می‌کنیم.
*   **برای کلاس Y=0:**
    *   نمونه‌ها: (1.5, 0.3), (0.9, 0.5), (0.3, 0.6)
    *   میانگین X1: `(1.5 + 0.9 + 0.3) / 3 = 2.7 / 3 = 0.9`
    *   میانگین X2: `(0.3 + 0.5 + 0.6) / 3 = 1.4 / 3 ≈ 0.467`
    *   **m_0 = (0.9, 0.467)**

*   **برای کلاس Y=1:**
    *   نمونه‌ها: (2.1, 0.8), (0.7, 1.2), (1.8, 1.0)
    *   میانگین X1: `(2.1 + 0.7 + 1.8) / 3 = 4.6 / 3 ≈ 1.533`
    *   میانگین X2: `(0.8 + 1.2 + 1.0) / 3 = 3.0 / 3 = 1.0`
    *   **m_1 = (1.533, 1.0)**

*   **برای کلاس Y=2:**
    *   نمونه‌ها: (2.5, 1.5), (2.0, 1.3), (1.2, 0.7)
    *   میانگین X1: `(2.5 + 2.0 + 1.2) / 3 = 5.7 / 3 = 1.9`
    *   میانگین X2: `(1.5 + 1.3 + 0.7) / 3 = 3.5 / 3 ≈ 1.167`
    *   **m_2 = (1.9, 1.167)**

**۲. ماتریس پراکندگی درون‌کلاسی (Within-class Scatter Matrix - Sw):** [۹]
`Sw = Σ_k Σ_(x ∈ C_k) (x - m_k) * (x - m_k)^T`
این ماتریس نشان‌دهنده پراکندگی نقاط داده **درون هر کلاس** است.
*   برای هر کلاس `k`، ماتریس کوواریانس نمونه‌ها را حول میانگین `m_k` خود محاسبه می‌کنیم. سپس این ماتریس‌ها را با هم جمع می‌کنیم. (محاسبه دستی دقیق این ماتریس زمانبر و پیچیده است، اما مفهوم آن مهم است.)

**۳. ماتریس پراکندگی بین‌کلاسی (Between-class Scatter Matrix - Sb):** [۹]
`Sb = Σ_k N_k * (m_k - m) * (m_k - m)^T`
این ماتریس نشان‌دهنده پراکندگی **بین میانگین‌های کلاس‌ها** است.
*   ابتدا میانگین کلی تمام داده‌ها (`m`) را محاسبه می‌کنیم. سپس با استفاده از تعداد نمونه‌ها در هر کلاس (`N_k`) و بردارهای میانگین کلاس‌ها (`m_k`)، ماتریس `Sb` را می‌سازیم.

**۲. ایجاد تک متغیر:**

**الف و ب) مراحل و محاسبات ایجاد تک متغیر:**
1.  **حل مسئله مقدار ویژه:** [۱۵۵]
    *   برای یافتن بهترین جهت (تک متغیر) برای نگاشت، باید مسئله مقدار ویژه `Sw^-1 * Sb * w = λ * w` را حل کنیم.
    *   `w`: بردار ویژه (Eigenvector) است که جهت تک متغیر جدید را نشان می‌دهد.
    *   `λ`: مقدار ویژه (Eigenvalue) مربوطه است.
    *   از آنجایی که ما به دنبال یک تک متغیر هستیم (کاهش ابعاد به ۱)، **بردار ویژه (`w`) مربوط به بزرگترین مقدار ویژه (`λ`)** را انتخاب می‌کنیم. این بردار، خطی است که بیشترین توانایی را برای جداسازی کلاس‌ها دارد.
2.  **نگاشت داده‌ها:**
    *   فرض کنید بردار ویژه انتخاب شده `w = (w1, w2)` باشد.
    *   سپس، هر نقطه داده اصلی `(X1, X2)` را می‌توان با ضرب داخلی با `w` به یک تک متغیر `LD` نگاشت کرد:
        `LD = w1 * X1 + w2 * X2`
    *   این `LD` همان تک متغیری است که توانایی جداسازی سه کلاس Y=0, Y=1, Y=2 را دارد.

**۳. ارزیابی مدل:**

**الف) عملکرد متغیر ایجاد شده (دقت و سایر معیارها):**
*   **ایجاد آستانه‌ها:** پس از نگاشت تمام نقاط به این تک متغیر `LD`، نقاط `LD` برای هر کلاس روی یک خط قرار می‌گیرند. برای جداسازی سه کلاس، نیاز به **دو آستانه (Threshold)** روی این خط `LD` داریم. این آستانه‌ها می‌توانند با بررسی توزیع نقاط `LD` برای هر کلاس تعیین شوند (مثلاً با پیدا کردن نقاطی که بهترین جداسازی را ایجاد می‌کنند).
*   **طبقه‌بندی:** هر نمونه بر اساس اینکه مقدار `LD` آن در کدام بازه بین آستانه‌ها قرار می‌گیرد، به یکی از کلاس‌های ۰، ۱ یا ۲ تخصیص می‌یابد.
*   **محاسبه دقت:** [۹۰]
    `Accuracy = (تعداد پیش‌بینی‌های صحیح) / (کل نمونه‌ها)`
*   **سایر معیارها:** برای طبقه‌بندی چندکلاسی، می‌توان از معیارهایی مانند **Precision، Recall و F1-Score** (محاسبه شده به صورت macro-average یا weighted-average برای در نظر گرفتن تعادل کلاس‌ها) استفاده کرد [۱۸۳]. همچنین می‌توان ماتریس درهم‌ریختگی (Confusion Matrix) را برای هر سه کلاس (۳x۳) ساخت و تعداد TP, TN, FP, FN را برای هر کلاس (نسبت به بقیه کلاس‌ها) محاسبه کرد.

**۴. بحث در مورد اهمیت LDA:** [۱۰, ۱۵۶]

**الف) اهمیت روش LDA در کاهش ابعاد و جداسازی کلاس‌ها:**
*   **حفظ اطلاعات تمایزدهنده کلاس:** اصلی‌ترین اهمیت LDA این است که **ابعاد را کاهش می‌دهد، در حالی که بیشترین اطلاعات مربوط به جداسازی کلاس‌ها را حفظ می‌کند** [۱۵۶]. این امر آن را به گزینه‌ای ایده‌آل برای پیش‌پردازش داده‌ها در مسائل طبقه‌بندی تبدیل می‌کند.
*   **بهبود عملکرد مدل:** با کاهش ابعاد و افزایش جدایی‌پذیری کلاس‌ها، مدل‌های طبقه‌بندی (که پس از LDA استفاده می‌شوند) می‌توانند عملکرد بهتری داشته باشند و با داده‌های کمتری آموزش ببینند [۱۰].
*   **جلوگیری از Curse of Dimensionality:** در داده‌های با ابعاد بالا، پدیده‌ای به نام "نفرین ابعاد" (Curse of Dimensionality) می‌تواند باعث مشکلات محاسباتی و کاهش عملکرد مدل شود. LDA با کاهش ابعاد، به کاهش این مشکل کمک می‌کند [۱۴].
*   **تفسیرپذیری:** ابعاد جدید (Linear Discriminants) که توسط LDA ایجاد می‌شوند، اغلب می‌توانند از نظر مفهومی تفسیر شوند و نشان دهند کدام ترکیب از ویژگی‌های اصلی، کلاس‌ها را بهتر از هم جدا می‌کند [۱۰].

---

#### **سوال ۴: ارزیابی مدل و بیش‌برازش** [۱۰]

**متن سوال:**
الف) منحنی درسستی (Accuracy Curve) را برای مدل یادگیری زیر جدول داده‌ها (Complexity 1 تا 4) بر روی داده‌های آموزشی و ارزیابی را نشان دهید.
ب) مشخص کنید برای داده‌های ارزیابی، کمینه بیش‌برازش (Overfitting) در چه پیچیدگی رخ می‌دهد.
ج) در این پیچیدگی، Precision و Recall را محاسبه نمایید.

**جدول داده‌ها:**
Complexity | P N | P N | P N | P N | Sum
-----------|-----|-----|-----|-----|------
           | C1  | C2  | C3  | C4  |
Actual     | P N | P N | P N | P N | Total
Training   |     |     |     |     |
P          | 300 900 | 600 600 | 900 300 | 1200 0 | 1200
N          | 225 75  | 150 150 | 75  225 | 0    300 | 300
Validation |     |     |     |     |
P          | 20  100 | 55  65  | 85  35  | 80   40  | 120
N          | 25  5   | 16  14  | 7   23  | 5    25  | 30

**پاسخ:**

این سوال **کاملاً مشابه سوال ۴ آزمون اول** است. محاسبات و تحلیل‌ها یکسان خواهد بود. برای جلوگیری از تکرار، خلاصه‌ای از نتایج را ارائه می‌دهم:

**الف) منحنی دقت (Accuracy Curve):**
(محاسبات دقیق در سوال ۴ آزمون اول آورده شده است.)

| Complexity | Training Accuracy | Validation Accuracy |
|:-----------|:------------------|:--------------------|
| 1          | 0.25              | 0.167               |
| 2          | 0.50              | 0.46                |
| 3          | 0.75              | 0.72                |
| 4          | 1.00              | 0.70                |

**تصویر مفهومی منحنی دقت:**
(همانند تصویر مفهومی ذکر شده در سوال ۴ آزمون اول: محور X پیچیدگی، محور Y دقت، دو خط برای دقت آموزشی و دقت اعتبارسنجی.)

**ب) کمینه بیش‌برازش (Minimal Overfitting):** [۹۲, ۱۶۸, ۱۷۱]
*   **بیش‌برازش** زمانی است که مدل روی داده‌های آموزشی خیلی خوب عمل می‌کند اما روی داده‌های جدید عملکرد ضعیفی دارد. این با یک شکاف بزرگ بین دقت آموزشی و دقت اعتبارسنجی مشخص می‌شود.
*   **در Complexity 4،** مدل به دقت ۱۰۰% در داده‌های آموزشی می‌رسد (که نشان‌دهنده حفظ کردن داده‌ها است)، اما دقت اعتبارسنجی آن ۷۰% است؛ این شکاف بزرگ نشان‌دهنده بیش‌برازش شدید است.
*   **در Complexity 3،** دقت آموزشی ۷۵% و دقت اعتبارسنجی ۷۲% است. این دو مقدار بسیار به هم نزدیک هستند و نشان‌دهنده این است که مدل در اینجا به خوبی تعمیم یافته است و **کمترین بیش‌برازش** را دارد [۱۷۱].

**بنابراین، کمینه بیش‌برازش در Complexity 3 رخ می‌دهد.**

**ج) محاسبه Precision و Recall در Complexity 3:** [۱۷۷]

*   **داده‌های اعتبارسنجی برای Complexity 3:**
    *   TP = 85
    *   FN = 35
    *   FP = 7
    *   TN = 23

*   **Precision (دقت):** `TP / (TP + FP) = 85 / (85 + 7) = 85 / 92 ≈ 0.924`
    *   این بدان معناست که از هر ۱۰۰ موردی که مدل به عنوان مثبت پیش‌بینی کرده است، تقریباً ۹۲.۴ مورد واقعاً مثبت بوده‌اند.

*   **Recall (بازیابی):** `TP / (TP + FN) = 85 / (85 + 35) = 85 / 120 ≈ 0.708`
    *   این بدان معناست که از هر ۱۰۰ مورد واقعاً مثبت در داده‌ها، مدل تقریباً ۷۰.۸ مورد را به درستی شناسایی کرده است.

این معیارها نشان می‌دهند که در Complexity 3، مدل از نظر پیش‌بینی‌های مثبت بسیار دقیق است، اما حدود ۲۹% از موارد مثبت واقعی را از دست می‌دهد.
